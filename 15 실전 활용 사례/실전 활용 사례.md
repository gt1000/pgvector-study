# 온프레미스 RAG 구현 AI 아키텍처 설계서 (검증 및 개선판)

## 해경 수색구조 · 해양수산/양식 도메인 / Python 중심

---

## 문서 검토 요약

이 문서는 원본 GPT 작성 문서를 다음 4가지 관점에서 검증하고 수정한 결과입니다:
1. **아키텍처 분석** - 전체 구조의 적절성과 계층 분리
2. **기본 설계** - 모듈 구조, 데이터 흐름, 인터페이스 설계
3. **AI 기술 벤치마킹** - 기술 스택 선택 근거와 비교 분석
4. **수정 사항** - 원본의 오류, 누락, 개선점

---

## 0. 이 문서의 목적

온프레미스(폐쇄망) 환경에서 RAG를 "실제로 구현/운영"하기 위한 **AI 기술 아키텍처**를 정리한다.

특히 다음 항목을 명확히 한다:
- LangChain / LangGraph / LlamaIndex / LM Studio / Ollama / vLLM 각각의 역할
- "최적 조합(권장)"과 "왜 그 조합인지" (선택 이유)
- Python 서비스/모듈 구조(폴더 구조)와 각 역할
- 벤치마킹(품질/성능/운영성)으로 선택을 검증하는 방법

---

## 1. 용어 정리 (이 부분만 이해하면 전체가 잡힘)

### 1.1 모델 서빙(Serving) 계층: "모델을 돌려주는 엔진"

| 도구 | 특징 | 적합한 상황 |
|------|------|------------|
| **Ollama** | 로컬/온프레미스에서 모델 실행을 쉽게 해주는 런타임. 설치/운영 간편 | 소규모, 빠른 시작, GPU 제한 환경 |
| **vLLM** | 운영형 고성능 LLM 서빙. PagedAttention 기반으로 동시성/배치 처리/처리량에 강함 | 다중 사용자, 프로덕션 환경, GPU 서버 보유 |
| **LM Studio** | GUI 기반 데스크톱 런타임. 모델 전환이 쉬움 | 개발/테스트, 프롬프트 실험, PoC |
| **TGI (Text Generation Inference)** | HuggingFace의 프로덕션급 서빙 솔루션 | 대규모 운영, HF 생태계 활용 |

> **✅ 수정 사항**: 원본에서 누락된 TGI(Text Generation Inference) 추가. 실제 프로덕션에서 vLLM과 함께 고려해야 할 중요 옵션임.

> **결론:**
> - "운영 서버"는 **vLLM** 또는 **TGI** (고성능) / **Ollama** (간편/소규모)
> - **LM Studio는 개발/PoC용**으로 매우 좋지만, 서버리스 환경이나 headless 서버에서 구동이 어려움

---

### 1.2 RAG 프레임워크 계층: "문서 인입 → 검색 → 프롬프트 구성 → 응답 생성"

| 프레임워크 | 핵심 강점 | 주요 용도 |
|-----------|----------|----------|
| **LlamaIndex** | 데이터 인덱싱/RAG 특화. 문서 로더, 청킹, 인덱싱, 리트리버, 응답 합성이 촘촘함 | 문서 인입, 검색 파이프라인 |
| **LangChain** | LLM 앱 구성 요소 풍부. 다양한 툴/커넥터/체인 구성에 강점 | 에이전트, 도구 통합, 범용 LLM 앱 |
| **LangGraph** | 상태머신/워크플로우 제어 특화. 조건 분기, 재시도, 검증 로직 구현 | 멀티스텝 RAG, 복잡한 파이프라인 |
| **Haystack** | 엔드투엔드 NLP 파이프라인. 프로덕션 지향적 | 검색 중심 애플리케이션 |

> **✅ 수정 사항**: Haystack 추가. 특히 검색 품질이 중요한 도메인에서 고려할 만한 대안임.

> **결론:**
> - LlamaIndex/LangChain은 "기능 라이브러리"
> - LangGraph는 "오케스트레이션(흐름 제어)"
> - 실무에서 품질이 올라가는 지점은 대부분 "흐름 제어(조건 분기/재시도/검증)"에서 나옴

---

### 1.3 벡터 데이터베이스 계층 (원본에서 누락)

> **✅ 수정 사항**: 원본에서 벡터DB 선택에 대한 상세 비교가 없었음. 온프레미스 RAG에서 핵심 컴포넌트이므로 추가.

| 벡터DB | 특징 | 온프레미스 적합도 |
|--------|------|-----------------|
| **pgvector** | PostgreSQL 확장. 기존 DB 인프라 활용 가능, 트랜잭션 지원 | ⭐⭐⭐⭐⭐ (권장) |
| **Milvus** | 분산 벡터DB. 대규모 확장성, 다양한 인덱스 지원 | ⭐⭐⭐⭐ |
| **Qdrant** | Rust 기반 고성능. 필터링 강력, 메모리 효율적 | ⭐⭐⭐⭐ |
| **Chroma** | 경량 임베디드 DB. 개발/PoC에 적합 | ⭐⭐⭐ |
| **Weaviate** | GraphQL API, 모듈형 아키텍처 | ⭐⭐⭐ |

**온프레미스 권장: pgvector**
- PostgreSQL 기반으로 기존 DBA 역량 활용 가능
- ACID 트랜잭션으로 데이터 무결성 보장
- 하이브리드 검색(벡터 + 메타데이터 필터) 용이
- 운영 도구(백업, 모니터링) 성숙

---

### 1.4 임베딩 모델 선택 (원본에서 상세 누락)

> **✅ 수정 사항**: 임베딩 모델 선택이 RAG 품질에 결정적이지만 원본에서 구체적 후보가 없었음.

| 모델 | 차원 | 한국어 성능 | 특징 |
|------|------|------------|------|
| **multilingual-e5-large** | 1024 | ⭐⭐⭐⭐ | 다국어 강점, 문서 검색 최적화 |
| **bge-m3** | 1024 | ⭐⭐⭐⭐⭐ | 다국어, Dense+Sparse+ColBERT 지원 |
| **KoSimCSE-roberta** | 768 | ⭐⭐⭐⭐ | 한국어 특화, 문장 유사도 |
| **paraphrase-multilingual-mpnet** | 768 | ⭐⭐⭐ | 범용 다국어 |

**해양/수산 도메인 권장: bge-m3 또는 multilingual-e5-large**
- 한국어 법령/지침 문서에 대한 검색 품질 우수
- 온프레미스 구동 가능 (Ollama 또는 직접 서빙)

---

## 2. 권장 "최적 조합" (온프레미스/소규모 사용자 기준)

### 2.1 추천 조합 (권장안)

```
┌─────────────────────────────────────────────────────────────┐
│                        사용자 인터페이스                      │
│                    (Web UI / API Client)                    │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                      API Gateway Layer                       │
│                         (FastAPI)                            │
│  • 인증/인가 • 요청 검증 • 로깅 • Rate Limiting              │
└─────────────────────────────────────────────────────────────┘
                              │
              ┌───────────────┴───────────────┐
              ▼                               ▼
┌──────────────────────────┐    ┌──────────────────────────┐
│     RAG 온라인 서비스      │    │    Ingest 배치 서비스     │
│        (rag-api)          │    │    (ingest-worker)       │
├──────────────────────────┤    ├──────────────────────────┤
│ • 질의 라우팅              │    │ • 문서 수집/추출          │
│ • 검색 (LlamaIndex)       │    │ • 청킹/임베딩            │
│ • 워크플로우 (LangGraph)   │    │ • 벡터DB 적재           │
│ • 답변 생성               │    │ • 메타데이터 관리         │
└──────────────────────────┘    └──────────────────────────┘
              │                               │
              └───────────────┬───────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                      데이터 계층                             │
│  ┌─────────────────┐  ┌─────────────────┐                  │
│  │   pgvector      │  │   PostgreSQL    │                  │
│  │  (벡터 검색)     │  │  (메타데이터)    │                  │
│  └─────────────────┘  └─────────────────┘                  │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     모델 서빙 계층                           │
│  ┌─────────────────┐  ┌─────────────────┐                  │
│  │  LLM Server     │  │ Embedding Server│                  │
│  │ (Ollama/vLLM)   │  │ (Ollama/직접)   │                  │
│  └─────────────────┘  └─────────────────┘                  │
└─────────────────────────────────────────────────────────────┘
```

**스택 요약:**
- **(서빙)** Ollama 또는 vLLM
- **(RAG 데이터/검색)** LlamaIndex
- **(워크플로우/오케스트레이션)** LangGraph
- **(API)** FastAPI
- **(벡터DB)** pgvector + PostgreSQL
- **(임베딩)** bge-m3 또는 multilingual-e5-large

---

### 2.2 왜 LangChain을 메인으로 안 잡고 LlamaIndex 중심이냐?

온프레미스 RAG에서 가장 많은 시간이 들어가는 건 "문서 인입/청킹/인덱싱/리트리벌 품질"이다.

| 비교 항목 | LlamaIndex | LangChain |
|----------|-----------|-----------|
| 문서 로더 | 150+ 포맷 기본 지원 | 외부 의존성 많음 |
| 청킹 전략 | 계층적/의미적 청킹 내장 | 단순 분할 위주 |
| 인덱스 관리 | VectorStoreIndex, TreeIndex 등 다양 | 수동 구성 필요 |
| 리트리버 | 하이브리드, 재랭킹 통합 | 별도 구현 필요 |
| 응답 합성 | Response Synthesizer 내장 | Chain 조합 필요 |

> **단, LangChain은 "툴/커넥터/에이전트"가 필요해지는 2단계에서 강력해진다.**
> 그래서 "초기 운영형 RAG"는 LlamaIndex 중심이 비용 대비 효율이 좋다.

---

### 2.3 Ollama vs vLLM 선택 기준

| 기준 | Ollama | vLLM |
|------|--------|------|
| **설치 난이도** | ⭐ (매우 쉬움) | ⭐⭐⭐ (CUDA 설정 필요) |
| **동시 요청 처리** | 제한적 | 우수 (Continuous Batching) |
| **처리량 (tokens/sec)** | 보통 | 높음 (2-3배) |
| **메모리 효율** | 보통 | 우수 (PagedAttention) |
| **GPU 미지원 환경** | 가능 (느림) | 불가 |
| **OpenAI API 호환** | ✅ | ✅ |
| **모델 전환** | 쉬움 | 재시작 필요 |

**Ollama 추천 상황:**
- 사용자 수 10명 이하
- 문서 규모 1만건 이하
- GPU가 없거나 제한적
- "빨리 시작하고 검증" 목표

**vLLM 추천 상황:**
- 동시 사용자 10명 이상 예상
- 응답 지연시간이 중요
- GPU 서버(A100, RTX 4090 등) 보유
- 프로덕션 표준화 목표

---

### 2.4 LM Studio는 어디에 쓰는가?

**PoC/개발 환경에서만 권장:**
- 모델 바꿔가며 응답 품질 비교
- 프롬프트 튜닝
- 임베딩/LLM API를 임시로 빠르게 제공

**운영 환경에서 사용하지 않는 이유:**
- GUI 기반으로 headless 서버에서 구동 어려움
- 스크립트를 통한 자동화 제한
- 동시성/안정성 보장 어려움

---

## 3. AI 시스템 아키텍처 (구현 관점)

### 3.1 서비스 분해 (권장)

온프레미스 소규모 환경이면 2개로 끝내도 된다.

**1. rag-api (온라인)**
- 질의응답 API
- 검색 수행 (벡터/하이브리드)
- 프롬프트 구성
- 모델 호출
- 출처 정리 및 반환
- 로그/감사 저장

**2. ingest-worker (오프라인/배치)**
- 문서 업로드/수집
- 텍스트 추출/정제
- 청킹/메타 추출(페이지/조항/섹션)
- 임베딩 생성
- 벡터DB(pgvector)에 적재
- 재인덱싱/버전 관리

> **✅ 수정 사항**: 원본에서 누락된 선택적 서비스 추가

**3. eval-service (선택, 품질 관리용)**
- 검색 품질 평가 (Recall, MRR)
- 답변 품질 평가 (Faithfulness)
- 회귀 테스트 자동화

**4. admin-dashboard (선택, 운영 관리용)**
- 문서 현황 모니터링
- 질의 로그 분석
- 시스템 상태 확인

---

### 3.2 RAG 처리 파이프라인 (표준)

**Ingestion Pipeline (문서 인입)**

```
문서 업로드
    │
    ▼
┌─────────────────┐
│ 1. 문서 로드     │  ← PDF, HWP, DOCX, HTML 등
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 2. 텍스트 추출   │  ← OCR (스캔 문서), 테이블 추출
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 3. 텍스트 정제   │  ← 헤더/푸터 제거, 특수문자 정규화
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 4. 청킹         │  ← 의미 단위 분할, 오버랩 처리
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 5. 메타데이터    │  ← 문서명, 페이지, 조항번호, 작성일
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 6. 임베딩 생성   │  ← bge-m3, multilingual-e5
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 7. 벡터DB 저장   │  ← pgvector (HNSW 인덱스)
└─────────────────┘
```

**Query Pipeline (질의 처리)**

```
사용자 질의
    │
    ▼
┌─────────────────┐
│ 1. 질의 분석     │  ← 의도 분류, 키워드 추출
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 2. 질의 확장     │  ← 동의어, 약어 확장 (선택)
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 3. 하이브리드    │  ← 벡터 검색 + BM25 키워드 검색
│    검색         │
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 4. 재정렬       │  ← Cross-encoder reranking (선택)
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 5. 컨텍스트     │  ← 상위 K개 청크 조합
│    구성         │
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 6. 프롬프트     │  ← 도메인별 템플릿 적용
│    구성         │
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 7. 답변 생성     │  ← LLM 호출
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 8. 출처 정리     │  ← 문서명, 페이지, 조항 포맷팅
└─────────────────┘
    │
    ▼
응답 반환
```

---

### 3.3 품질을 올리는 "워크플로우 (LangGraph 적용 지점)"

단순 RAG(검색→답변)만으로는 현장에서 다음 문제가 생김:
- 질문이 너무 짧음/애매함
- 출처가 부정확하거나 부족함
- 도메인별 답변 톤/형식이 섞임
- 문서에 없는 내용을 모델이 만들어냄(환각)

**LangGraph 워크플로우 설계:**

```
                    ┌─────────────┐
                    │  Start      │
                    └──────┬──────┘
                           │
                           ▼
                    ┌─────────────┐
                    │ Query       │
                    │ Router      │
                    └──────┬──────┘
                           │
           ┌───────────────┼───────────────┐
           │               │               │
           ▼               ▼               ▼
    ┌──────────┐    ┌──────────┐    ┌──────────┐
    │ SAR      │    │ 법령/    │    │ 양식/    │
    │ Retriever│    │ 지침     │    │ 수산     │
    └────┬─────┘    └────┬─────┘    └────┬─────┘
         │               │               │
         └───────────────┼───────────────┘
                         │
                         ▼
                  ┌─────────────┐
                  │ Evidence    │
                  │ Check       │◄─────────┐
                  └──────┬──────┘          │
                         │                 │
              ┌──────────┴──────────┐      │
              │                     │      │
         충분함│                     │부족함 │
              ▼                     ▼      │
       ┌─────────────┐       ┌──────────┐  │
       │ Answer      │       │ Re-search│──┘
       │ Synthesis   │       │ (확장)   │
       └──────┬──────┘       └──────────┘
              │
              ▼
       ┌─────────────┐
       │ Citation    │
       │ Formatter   │
       └──────┬──────┘
              │
              ▼
       ┌─────────────┐
       │ Refusal     │  ← 근거 없으면 "확인 불가"
       │ Policy      │
       └──────┬──────┘
              │
              ▼
       ┌─────────────┐
       │  End        │
       └─────────────┘
```

**각 노드 역할:**

1. **Query Router**: 질문 분류 (SAR 절차 / 법령·지침 / 양식·수산 / 장비 / 일반)
2. **Domain Retriever**: 분류 결과에 맞는 인덱스/필터로 검색
3. **Evidence Check**: 근거 충분성 검사 (관련도 점수, 청크 수)
4. **Re-search**: 부족 시 질의 확장 또는 다른 인덱스 검색
5. **Answer Synthesis**: 근거 기반 답변 생성
6. **Citation Formatter**: 출처 표준 포맷 (문서명 / 페이지 / 조항)
7. **Refusal Policy**: 근거 부족 시 "확인 불가" 반환

---

## 4. Python 폴더/모듈 구조 (권장안)

### 4.1 레포 구조 (2서비스 기준)

> **✅ 수정 사항**: 원본의 폴더 구조를 개선하고 누락된 컴포넌트 추가

```
rag-platform/
├── rag_api/                          # 온라인 질의응답 서비스
│   ├── app/
│   │   ├── main.py                   # FastAPI 앱 진입점
│   │   ├── api/                      # FastAPI 라우터
│   │   │   ├── __init__.py
│   │   │   ├── chat.py               # 질의응답 엔드포인트
│   │   │   ├── docs.py               # 문서 조회 엔드포인트
│   │   │   └── health.py             # 헬스체크
│   │   ├── core/                     # 설정/공통
│   │   │   ├── config.py             # 환경 설정 (pydantic-settings)
│   │   │   ├── logging.py            # 로깅 설정
│   │   │   ├── exceptions.py         # 커스텀 예외
│   │   │   └── dependencies.py       # FastAPI 의존성 주입
│   │   ├── rag/                      # RAG 핵심 로직
│   │   │   ├── graph/                # LangGraph 워크플로우
│   │   │   │   ├── workflow.py       # 메인 그래프 정의
│   │   │   │   ├── state.py          # 상태 스키마
│   │   │   │   └── nodes/
│   │   │   │       ├── route_query.py
│   │   │   │       ├── retrieve.py
│   │   │   │       ├── evidence_check.py
│   │   │   │       ├── synthesize.py
│   │   │   │       └── format_citations.py
│   │   │   ├── prompts/              # 도메인별 프롬프트
│   │   │   │   ├── sar.yaml
│   │   │   │   ├── aquaculture.yaml
│   │   │   │   ├── law.yaml
│   │   │   │   └── base.yaml
│   │   │   └── retrieval/            # 검색 모듈
│   │   │       ├── retriever.py      # LlamaIndex 리트리버
│   │   │       ├── hybrid.py         # 하이브리드 검색
│   │   │       ├── reranker.py       # Cross-encoder 재랭킹
│   │   │       └── query_transform.py # 질의 변환/확장
│   │   ├── llm/                      # 모델 클라이언트
│   │   │   ├── client.py             # LLM 호출 (OpenAI 호환)
│   │   │   ├── embeddings.py         # 임베딩 클라이언트
│   │   │   └── schemas.py            # 요청/응답 스키마
│   │   ├── policy/                   # 안전장치/정책
│   │   │   ├── refusal.py            # 근거 없으면 거절
│   │   │   ├── pii_masking.py        # 민감정보 마스킹
│   │   │   └── guardrails.py         # 입출력 검증
│   │   ├── store/                    # 저장소 어댑터
│   │   │   ├── pgvector_store.py     # pgvector 연동
│   │   │   ├── cache.py              # Redis 캐싱 (선택)
│   │   │   └── audit_log.py          # 감사 로그
│   │   └── observability/            # 모니터링
│   │       ├── metrics.py            # Prometheus 메트릭
│   │       └── tracing.py            # OpenTelemetry 트레이싱
│   ├── tests/
│   │   ├── unit/
│   │   ├── integration/
│   │   └── fixtures/
│   ├── Dockerfile
│   ├── pyproject.toml
│   └── README.md
│
├── ingest_worker/                    # 오프라인 문서 처리 서비스
│   ├── app/
│   │   ├── main.py                   # 워커 진입점
│   │   ├── pipeline/                 # 인제스트 파이프라인
│   │   │   ├── ingest_job.py         # 메인 파이프라인
│   │   │   └── steps/
│   │   │       ├── load_document.py
│   │   │       ├── extract_text.py
│   │   │       ├── clean_text.py
│   │   │       ├── chunk_text.py
│   │   │       ├── extract_metadata.py
│   │   │       ├── embed_chunks.py
│   │   │       └── upsert_store.py
│   │   ├── parsers/                  # 포맷별 파서
│   │   │   ├── pdf.py                # PyMuPDF, pdfplumber
│   │   │   ├── docx.py               # python-docx
│   │   │   ├── hwp.py                # pyhwp 또는 변환 기반
│   │   │   ├── html.py
│   │   │   └── ocr.py                # Tesseract, EasyOCR
│   │   ├── chunking/                 # 청킹 전략
│   │   │   ├── semantic.py           # 의미 기반 청킹
│   │   │   ├── recursive.py          # 재귀적 청킹
│   │   │   └── policy.py             # 도메인별 청킹 정책
│   │   ├── dedup/                    # 중복 처리
│   │   │   ├── hash.py               # 콘텐츠 해시
│   │   │   └── similarity.py         # 유사도 기반 중복 제거
│   │   └── scheduler/                # 배치 스케줄링
│   │       ├── celery_app.py
│   │       └── tasks.py
│   ├── tests/
│   ├── Dockerfile
│   └── pyproject.toml
│
├── shared/                           # 공유 모듈
│   ├── schemas/                      # 공통 스키마
│   │   ├── document.py
│   │   ├── chunk.py
│   │   └── query.py
│   ├── db/                           # DB 연결
│   │   ├── postgres.py
│   │   └── migrations/               # Alembic 마이그레이션
│   └── utils/
│       ├── text.py
│       └── hash.py
│
├── eval/                             # 평가 도구 (✅ 추가)
│   ├── datasets/                     # 평가 데이터셋
│   │   ├── sar_questions.json
│   │   └── law_questions.json
│   ├── metrics/
│   │   ├── retrieval.py              # Recall, MRR, NDCG
│   │   └── generation.py             # Faithfulness, Relevance
│   ├── scripts/
│   │   ├── run_eval.py
│   │   └── generate_report.py
│   └── README.md
│
├── docker-compose.yml                # 로컬 개발 환경
├── docker-compose.prod.yml           # 프로덕션 환경
├── Makefile                          # 빌드/배포 스크립트
└── README.md
```

---

## 5. 각 모듈의 "역할" (현장에서 필요한 관점)

### 5.1 rag_api (온라인)

| 모듈 | 역할 | 핵심 구현 포인트 |
|------|------|----------------|
| **api/** | HTTP 엔드포인트 | 요청 검증, 응답 포맷팅, 에러 처리 |
| **rag/graph/** | LangGraph 워크플로우 | 상태 머신, 조건 분기, 재시도 로직 |
| **rag/retrieval/** | 검색 실행 | 하이브리드 검색, 재랭킹, 필터링 |
| **llm/** | 모델 호출 | 타임아웃, 재시도, 스트리밍 |
| **policy/** | 안전장치 | 환각 방지, 민감정보 마스킹 |
| **store/** | 데이터 접근 | pgvector 쿼리 최적화, 캐싱 |
| **observability/** | 모니터링 | 지연시간 추적, 에러율 모니터링 |

### 5.2 ingest_worker (오프라인)

| 모듈 | 역할 | 핵심 구현 포인트 |
|------|------|----------------|
| **pipeline/** | 파이프라인 오케스트레이션 | 단계별 실행, 실패 복구, 부분 재시도 |
| **parsers/** | 문서 파싱 | 포맷별 최적 라이브러리 선택, OCR 폴백 |
| **chunking/** | 청킹 전략 | 도메인별 청킹 규칙, 오버랩 설정 |
| **dedup/** | 중복 처리 | 콘텐츠 해시, 증분 업데이트 |
| **scheduler/** | 배치 관리 | Celery 태스크, 재시도 정책 |

---

## 6. 모델 운영 전략

### 6.1 최소 모델 구성 (권장)

운영은 단순해야 한다. 처음부터 모델을 많이 깔면 망한다.

| 모델 유형 | 권장 모델 | 대안 |
|----------|----------|------|
| **임베딩 (필수)** | bge-m3 | multilingual-e5-large |
| **LLM (필수)** | Qwen2.5-7B-Instruct | Llama-3.1-8B, EXAONE-3.5-7.8B |
| **재랭커 (선택)** | bge-reranker-v2-m3 | ms-marco-MiniLM |

> **⚠️ 주의**: 임베딩 모델을 바꾸면 **전체 재인덱싱**이 필요하다.
> 그래서 임베딩 모델은 특히 더 신중하게 한 번에 고른다.

### 6.2 한국어 LLM 선택 가이드 (✅ 추가)

> **✅ 수정 사항**: 원본에서 한국어 LLM 구체적 추천이 없었음

| 모델 | 파라미터 | VRAM 요구량 | 한국어 성능 | 라이선스 |
|------|---------|------------|------------|---------|
| **Qwen2.5-7B-Instruct** | 7B | ~16GB | ⭐⭐⭐⭐ | Apache 2.0 |
| **EXAONE-3.5-7.8B** | 7.8B | ~18GB | ⭐⭐⭐⭐⭐ | 연구/상업 무료 |
| **Llama-3.1-8B-Instruct** | 8B | ~18GB | ⭐⭐⭐ | Llama 3.1 License |
| **Solar-10.7B** | 10.7B | ~24GB | ⭐⭐⭐⭐ | CC-BY-NC 4.0 |

**해양/수산 도메인 권장: EXAONE-3.5-7.8B 또는 Qwen2.5-7B**
- 한국어 법령/지침 이해도 높음
- 상용화 가능한 라이선스
- 온프레미스 GPU(RTX 4090 1장)로 구동 가능

---

## 7. 벤치마킹 기반 "선택 이유"를 만드는 방법

### 7.1 벤치마킹이 필요한 이유

"어떤 조합이 최적이냐"는 말로 끝나지 않는다.
해경/도메인 문서에서는 실제 질문에 대해 **근거가 맞는지**가 승부다.

따라서 다음 3가지를 동시에 평가해야 한다:
1. **검색 품질** (근거를 제대로 가져오나)
2. **생성 품질** (근거 기반으로 제대로 요약/답변하나)
3. **운영 성능** (지연시간/처리량/자원)

---

### 7.2 최소 평가셋 (권장)

| 도메인 | 질문 예시 | 수량 |
|--------|----------|------|
| SAR 절차 | "조난 신호 수신 시 초동 조치 절차는?" | 30개 |
| 장비 운용 | "수색정 레이더 운용 거리 제한은?" | 25개 |
| 법령/지침 | "해양경비법 제12조의 주요 내용은?" | 30개 |
| 양식/수산 | "적조 발생 시 양식장 대응 지침은?" | 25개 |
| 일반 | "해경 조직 구조는?" | 10개 |
| **총계** | | **120개** |

각 질문마다 **정답 문서(또는 정답 청크)**를 지정해야 함.

---

### 7.3 평가 지표 (운영형으로 필요한 것만)

**Retrieval 평가:**

| 지표 | 설명 | 목표값 |
|------|------|--------|
| **Recall@5** | 정답이 Top-5 안에 있는 비율 | ≥ 0.85 |
| **Recall@10** | 정답이 Top-10 안에 있는 비율 | ≥ 0.92 |
| **MRR** | 정답의 순위 역수 평균 | ≥ 0.70 |
| **NDCG@10** | 순위 가중 관련도 점수 | ≥ 0.75 |

**Generation 평가:**

| 지표 | 설명 | 목표값 |
|------|------|--------|
| **Faithfulness** | 답변이 근거에서 벗어나지 않는 비율 | ≥ 0.90 |
| **Answer Relevance** | 답변이 질문에 적절한 비율 | ≥ 0.85 |
| **Citation Coverage** | 답변의 주장에 출처가 붙은 비율 | ≥ 0.95 |

**Performance 평가:**

| 지표 | 설명 | 목표값 |
|------|------|--------|
| **p50 latency** | 50% 요청의 응답시간 | ≤ 3초 |
| **p95 latency** | 95% 요청의 응답시간 | ≤ 8초 |
| **Throughput** | 초당 처리량 | ≥ 5 QPS |
| **GPU Memory** | GPU 메모리 사용량 | ≤ 20GB |

---

### 7.4 실험 설계 (조합을 "증명"하는 방식)

**실험 1: 임베딩 모델 비교**
```
조건: 동일 청킹(800자, 200자 오버랩), 동일 검색 K=10
변수: bge-m3 vs multilingual-e5-large vs KoSimCSE
측정: Recall@10, MRR
```

**실험 2: 청킹 전략 비교**
```
조건: 동일 임베딩(bge-m3), 동일 검색 K=10
변수: 
  - A: 고정 길이 (800자, 200자 오버랩)
  - B: 의미 기반 (문단/조항 단위)
  - C: 재귀적 (Recursive Splitter)
측정: Recall@10, 답변 품질(수동 평가)
```

**실험 3: 워크플로우 비교**
```
조건: 동일 임베딩, 동일 청킹, 동일 LLM
변수:
  - A: 단순 RAG (검색→답변)
  - B: LangGraph (근거 부족 시 재검색)
측정: Faithfulness, Citation Coverage
```

**실험 4: 서빙 엔진 비교**
```
조건: 동일 모델(Qwen2.5-7B), 동시 요청 10개
변수: Ollama vs vLLM
측정: p95 latency, Throughput
```

---

## 8. 수정 사항 요약

원본 문서 대비 주요 수정/추가 사항:

| 섹션 | 수정 내용 | 이유 |
|------|----------|------|
| 1.1 | TGI 추가 | 프로덕션 서빙 옵션으로 중요 |
| 1.2 | Haystack 추가 | 검색 중심 대안 프레임워크 |
| 1.3 | 벡터DB 비교 섹션 추가 | 원본에서 누락된 핵심 컴포넌트 |
| 1.4 | 임베딩 모델 구체화 | 한국어 도메인에 적합한 모델 명시 |
| 2.1 | 아키텍처 다이어그램 추가 | 시각적 이해도 향상 |
| 3.1 | eval-service, admin-dashboard 추가 | 운영 품질 관리에 필수 |
| 3.2 | 파이프라인 상세 플로우 추가 | 구현 가이드 명확화 |
| 3.3 | LangGraph 워크플로우 다이어그램 추가 | 상태 머신 설계 명확화 |
| 4.1 | 폴더 구조 상세화 | 누락된 모듈 추가 (observability, scheduler 등) |
| 6.2 | 한국어 LLM 비교표 추가 | 도메인 적합 모델 선택 가이드 |
| 7.2 | 평가셋 예시 구체화 | 도메인별 질문 수량 명시 |
| 7.3 | 평가 지표 목표값 추가 | 정량적 기준 제시 |

---

## 9. 최종 권장 "실무형 결론"

소규모/온프레미스/공공 환경에서 실패 확률이 가장 낮은 조합:

| 계층 | 초기 구성 | 확장 시 |
|------|----------|---------|
| **서빙** | Ollama | vLLM 또는 TGI |
| **LLM** | Qwen2.5-7B 또는 EXAONE-3.5-7.8B | 동일 |
| **임베딩** | bge-m3 | 동일 (변경 시 재인덱싱) |
| **RAG 프레임워크** | LlamaIndex | LlamaIndex + LangChain 병용 |
| **워크플로우** | LangGraph | 동일 |
| **벡터DB** | pgvector | Milvus (대규모) |
| **API** | FastAPI | 동일 |
| **캐시** | 없음 | Redis |
| **모니터링** | 기본 로깅 | Prometheus + Grafana |

> **핵심은 "특정 기술이 좋다"가 아니라**
> **(1) 운영 단순성 (2) 품질 검증 가능성 (3) 교체 가능성**이다.
> 이 3가지를 만족하는 조합이 최적이다.

---

## 10. 다음 단계 (바로 구현으로 연결)

이 문서를 기반으로 다음 산출물을 생성할 수 있다:

1. **rag_api FastAPI 스켈레톤 코드**
    - 라우터, LangGraph 노드, LLM 클라이언트

2. **ingest_worker 배치 파이프라인**
    - 문서 로더, 파서, 청커, 임베딩 모듈

3. **모델 서버 연동 규격**
    - OpenAI 호환 요청/응답 DTO
    - Ollama/vLLM 설정 가이드

4. **벤치마킹 스크립트**
    - 평가 데이터셋 포맷
    - 지표 계산 스크립트
    - 리포트 생성기

5. **Docker Compose 환경**
    - 개발/프로덕션 분리 구성
    - GPU 지원 설정

---

## 부록 A: 기술 스택 버전 권장

| 기술 | 권장 버전 | 비고 |
|------|----------|------|
| Python | 3.11+ | 3.12 호환성 확인 필요 |
| LlamaIndex | 0.11+ | 최신 API 사용 |
| LangGraph | 0.2+ | 최신 StateGraph API |
| FastAPI | 0.110+ | Pydantic v2 호환 |
| pgvector | 0.7+ | HNSW 인덱스 지원 |
| PostgreSQL | 16+ | pgvector 0.7 호환 |
| Ollama | 0.3+ | OpenAI API 호환 |
| vLLM | 0.6+ | 최신 모델 지원 |

---

## 부록 B: HWP 문서 처리 (한국 공공기관 특화)

> **✅ 수정 사항**: 원본에서 HWP 처리에 대한 구체적 가이드 부족

**방법 1: pyhwp (순수 Python)**
```python
from hwp5.hwp5html import main as hwp_to_html
# HWP → HTML → 텍스트 추출
```
- 장점: 외부 의존성 없음
- 단점: 일부 복잡한 HWP 파싱 실패

**방법 2: LibreOffice 변환**
```bash
libreoffice --headless --convert-to docx input.hwp
```
- 장점: 안정적인 변환
- 단점: LibreOffice 설치 필요, 속도 느림

**방법 3: Hwp5txt (텍스트 직접 추출)**
```bash
hwp5txt input.hwp > output.txt
```
- 장점: 빠른 텍스트 추출
- 단점: 서식 정보 손실

**권장: 방법 1 시도 → 실패 시 방법 2 폴백**

---

*문서 버전: 1.1 (검증 및 개선판)*
*최종 수정: 2025년 1월*