# ğŸ“˜ 14. ìŠ¤ì¼€ì¼ë§ (Scaling)

pgvectorë¥¼ í™œìš©í•œ ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œì´ **ìˆ˜ë°±ë§Œ~ìˆ˜ì–µ ê±´ ì´ìƒ**ìœ¼ë¡œ í™•ì¥ë  ë•Œ,  
ë‹¨ì¼ ì„œë²„ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ë§ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.

> ğŸ” **í•µì‹¬ ê°œë…:**
> - **Vertical Scaling**: ì„œë²„ ì„±ëŠ¥ í–¥ìƒ (CPU/RAM ì¦ê°€)
> - **Horizontal Scaling**: ì„œë²„ ìˆ˜ ì¦ê°€ (ìƒ¤ë”©/ë³µì œ)
> - **Replica**: ì½ê¸° ë¶€í•˜ ë¶„ì‚°, ê³ ê°€ìš©ì„± í™•ë³´
> - **Sharding**: ë°ì´í„° ë¶„ì‚° ì €ì¥, ë³‘ë ¬ ì²˜ë¦¬

---

## 1) Vertical Scaling (ìˆ˜ì§ í™•ì¥)

### ê°œë…

ë‹¨ì¼ ì„œë²„ì˜ **í•˜ë“œì›¨ì–´ ì„±ëŠ¥ì„ í–¥ìƒ**ì‹œì¼œ ì²˜ë¦¬ ëŠ¥ë ¥ì„ ë†’ì´ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

### í™•ì¥ ì „ëµ

| ë¦¬ì†ŒìŠ¤ | ê¸°ë³¸ | ì¤‘ê¸‰ | ê³ ê¸‰ | ì˜í–¥ |
|--------|------|------|------|------|
| **CPU** | 4 cores | 8 cores | 16+ cores | ì¸ë±ìŠ¤ ë¹Œë“œ, ë³‘ë ¬ ì¿¼ë¦¬ |
| **RAM** | 16GB | 64GB | 128GB+ | ìºì‹œ, ì¸ë±ìŠ¤ ë©”ëª¨ë¦¬ |
| **Storage** | HDD | SSD | NVMe SSD | I/O ì†ë„ |
| **Network** | 1Gbps | 10Gbps | 25Gbps+ | í´ë¼ì´ì–¸íŠ¸ ì‘ë‹µ |

### ë‹¨ê³„ë³„ ì—…ê·¸ë ˆì´ë“œ

#### 1ë‹¨ê³„: 16GB RAM â†’ 64GB RAM
```sql
-- ë©”ëª¨ë¦¬ ì¦ê°€ í›„ PostgreSQL íŒŒë¼ë¯¸í„° ì¡°ì •
ALTER SYSTEM SET shared_buffers = '16GB';  -- ê¸°ì¡´ 4GB
ALTER SYSTEM SET effective_cache_size = '48GB';  -- ê¸°ì¡´ 12GB
ALTER SYSTEM SET maintenance_work_mem = '4GB';  -- ê¸°ì¡´ 1GB
ALTER SYSTEM SET work_mem = '256MB';  -- ê¸°ì¡´ 64MB

-- ì ìš©
SELECT pg_reload_conf();
```

**íš¨ê³¼:**
- ì¸ë±ìŠ¤ ë¹Œë“œ ì‹œê°„: 45ë¶„ â†’ 20ë¶„ (2.25ë°° í–¥ìƒ)
- ê²€ìƒ‰ ì†ë„: ìºì‹œ íˆíŠ¸ìœ¨ 85% â†’ 98%

#### 2ë‹¨ê³„: SSD â†’ NVMe SSD
```bash
# ë””ìŠ¤í¬ I/O ì„±ëŠ¥ ì¸¡ì •
sudo hdparm -t /dev/sda  # HDD: ~120 MB/s
sudo hdparm -t /dev/nvme0n1  # NVMe: ~3500 MB/s

# PostgreSQL ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
pg_dump -U postgres -d study > backup.sql
# NVMe ë””ìŠ¤í¬ë¡œ ì´ë™
mv /var/lib/postgresql/data /mnt/nvme/postgresql/data
# ë³µì›
psql -U postgres -d study < backup.sql
```

**íš¨ê³¼:**
- ì¸ë±ìŠ¤ ìŠ¤ìº” ì†ë„: 30% í–¥ìƒ
- VACUUM/ANALYZE ì‹œê°„: 50% ë‹¨ì¶•

#### 3ë‹¨ê³„: CPU 8 cores â†’ 16 cores
```sql
-- ë³‘ë ¬ ì›Œì»¤ ì¦ê°€
ALTER SYSTEM SET max_parallel_workers_per_gather = 8;  -- ê¸°ì¡´ 4
ALTER SYSTEM SET max_worker_processes = 16;  -- ê¸°ì¡´ 8
ALTER SYSTEM SET max_parallel_workers = 16;  -- ê¸°ì¡´ 8

-- ë³‘ë ¬ ì¸ë±ìŠ¤ ë¹Œë“œ
SET max_parallel_maintenance_workers = 8;
CREATE INDEX idx_embedding_parallel ON embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**íš¨ê³¼:**
- ì¸ë±ìŠ¤ ë¹Œë“œ: ë³‘ë ¬í™”ë¡œ 40% ë‹¨ì¶•
- ë³µì¡í•œ ì§‘ê³„ ì¿¼ë¦¬: 2~3ë°° í–¥ìƒ

### Vertical Scaling í•œê³„

| ë°ì´í„° ê·œëª¨ | ê¶Œì¥ ì„œë²„ ìŠ¤í™ | ë¹„ìš© | í™•ì¥ì„± |
|------------|--------------|------|--------|
| **~1ë°±ë§Œ** | 16GB RAM, 8 cores | $ | âœ… ì¶©ë¶„ |
| **~1ì²œë§Œ** | 64GB RAM, 16 cores | $$ | âœ… ê°€ëŠ¥ |
| **~1ì–µ** | 128GB RAM, 32 cores | $$$$ | âš ï¸ ì œí•œì  |
| **1ì–µ+** | 256GB+ RAM, 64+ cores | $$$$$ | âŒ ë¹„í˜„ì‹¤ì  |

> ğŸ’¡ **1ì–µ ê±´ ì´ìƒì—ì„œëŠ” Horizontal Scaling í•„ìˆ˜**

---

## 2) Horizontal Scaling (ìˆ˜í‰ í™•ì¥)

### ê°œë…

ì—¬ëŸ¬ ì„œë²„ë¡œ **ë°ì´í„°ì™€ ë¶€í•˜ë¥¼ ë¶„ì‚°**í•˜ì—¬ ì²˜ë¦¬ ëŠ¥ë ¥ì„ í™•ì¥í•©ë‹ˆë‹¤.

### ì£¼ìš” ì „ëµ

| ì „ëµ | ëª©ì  | ë°©ì‹ | ë³µì¡ë„ |
|------|------|------|--------|
| **Replication** | ì½ê¸° ë¶€í•˜ ë¶„ì‚° | Master-Replica | ë‚®ìŒ |
| **Sharding** | ë°ì´í„° ë¶„ì‚° | ìˆ˜í‰ íŒŒí‹°ì…”ë‹ | ë†’ìŒ |
| **Connection Pooling** | ì—°ê²° ê´€ë¦¬ | PgBouncer/Pgpool | ë‚®ìŒ |

### ì•„í‚¤í…ì²˜ ë¹„êµ

#### ë‹¨ì¼ ì„œë²„ (Vertical)
```
         Client
            â†“
    [PostgreSQL Server]
    - 100M vectors
    - All queries
```

#### Replication (ì½ê¸° ë¶„ì‚°)
```
         Client
            â†“
    [Master (Write)]
      â†“    â†“    â†“
   [R1] [R2] [R3]  (Read Only)
```

#### Sharding (ë°ì´í„° ë¶„ì‚°)
```
         Client
            â†“
     [Application]
       â†™    â†“    â†˜
   [S1]  [S2]  [S3]
   33M   33M   33M vectors
```

---

## 3) Replica êµ¬ì„± (ì½ê¸° ë¶€í•˜ ë¶„ì‚°)

### PostgreSQL Streaming Replication

Master-Replica êµ¬ì¡°ë¡œ ì½ê¸° ì¿¼ë¦¬ë¥¼ ì—¬ëŸ¬ ì„œë²„ë¡œ ë¶„ì‚°í•©ë‹ˆë‹¤.

#### Master ì„¤ì •
```sql
-- postgresql.conf (Master)
wal_level = replica
max_wal_senders = 10
max_replication_slots = 10
hot_standby = on

-- pg_hba.conf (Master)
host replication replicator 192.168.1.0/24 md5
```
```bash
# Replication ì‚¬ìš©ì ìƒì„±
psql -U postgres -c "CREATE USER replicator REPLICATION LOGIN PASSWORD 'replica_password';"
```

#### Replica ì„¤ì •
```bash
# Replica ì„œë²„ì—ì„œ Base Backup
pg_basebackup -h master_ip -D /var/lib/postgresql/data -U replicator -P -v -R

# postgresql.conf (Replica)
hot_standby = on

# ìë™ ìƒì„±ëœ standby.signal í™•ì¸
ls /var/lib/postgresql/data/standby.signal

# PostgreSQL ì¬ì‹œì‘
sudo systemctl restart postgresql
```

#### ë³µì œ ìƒíƒœ í™•ì¸
```sql
-- Masterì—ì„œ ì‹¤í–‰
SELECT 
    client_addr,
    state,
    sent_lsn,
    write_lsn,
    replay_lsn,
    sync_state
FROM pg_stat_replication;

-- ì¶œë ¥ ì˜ˆì‹œ:
-- client_addr  | state     | sent_lsn  | write_lsn | replay_lsn | sync_state
-- -------------|-----------|-----------|-----------|------------|------------
-- 192.168.1.10 | streaming | 0/3000000 | 0/3000000 | 0/3000000  | async
```

---

## 4) Sharding (ë°ì´í„° ë¶„ì‚°)
### Citus í™•ì¥ì„ ì´ìš©í•œ ìƒ¤ë”©

CitusëŠ” PostgreSQLì„ ìˆ˜í‰ í™•ì¥í•  ìˆ˜ ìˆëŠ” í™•ì¥ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.

#### Citus ì„¤ì¹˜ (Docker Compose)
```yaml
# docker-compose.yml
version: '3.8'

services:
  master:
    image: citusdata/citus:12.1
    container_name: citus_master
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - master_data:/var/lib/postgresql/data

  worker1:
    image: citusdata/citus:12.1
    container_name: citus_worker1
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - worker1_data:/var/lib/postgresql/data

  worker2:
    image: citusdata/citus:12.1
    container_name: citus_worker2
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - worker2_data:/var/lib/postgresql/data

volumes:
  master_data:
  worker1_data:
  worker2_data:
```

#### Citus ì„¤ì •
```sql
-- Master ë…¸ë“œì—ì„œ ì‹¤í–‰
CREATE EXTENSION citus;

-- Worker ë…¸ë“œ ì¶”ê°€
SELECT citus_add_node('citus_worker1', 5432);
SELECT citus_add_node('citus_worker2', 5432);

-- ë…¸ë“œ í™•ì¸
SELECT * FROM citus_get_active_worker_nodes();

-- ë¶„ì‚° í…Œì´ë¸” ìƒì„±
CREATE TABLE embeddings (
    id BIGSERIAL,
    user_id BIGINT,
    content TEXT,
    embedding VECTOR(768)
);

-- í…Œì´ë¸” ë¶„ì‚° (user_id ê¸°ì¤€ ìƒ¤ë”©)
SELECT create_distributed_table('embeddings', 'user_id');

-- pgvector í™•ì¥ì€ ê° Workerì—ë„ ì„¤ì¹˜ í•„ìš”
\c - - citus_worker1
CREATE EXTENSION vector;

\c - - citus_worker2
CREATE EXTENSION vector;
```

#### ë¶„ì‚° ê²€ìƒ‰
```sql
-- íŠ¹ì • ì‚¬ìš©ìì˜ ë²¡í„° ê²€ìƒ‰ (ë‹¨ì¼ ìƒ¤ë“œë§Œ ì ‘ê·¼)
SELECT id, content
FROM embeddings
WHERE user_id = 12345
ORDER BY embedding <=> '[...]'::vector(768)
LIMIT 10;

-- ì „ì²´ ìƒ¤ë“œ ê²€ìƒ‰ (ëª¨ë“  Worker ë³‘ë ¬ ì‹¤í–‰)
SELECT id, content
FROM embeddings
ORDER BY embedding <=> '[...]'::vector(768)
LIMIT 10;
```

### Citus ì¥ë‹¨ì 

| êµ¬ë¶„ | ì¥ì  | ë‹¨ì  |
|------|------|------|
| **ì¥ì ** | PostgreSQL ë„¤ì´í‹°ë¸Œ<br>ë³‘ë ¬ ì¿¼ë¦¬<br>ìë™ ë¶„ì‚° | ë³µì¡í•œ ì„¤ì •<br>JOIN ì œì•½<br>Citus ë¼ì´ì„¼ìŠ¤ ê³ ë ¤ |
| **ì í•©** | ìˆ˜ì–µ~ìˆ˜ì‹­ì–µ ë°ì´í„°<br>ë©€í‹°í…Œë„ŒíŠ¸ | - |
| **ë¶€ì í•©** | ì†Œê·œëª¨ ë°ì´í„° | ë³µì¡í•œ íŠ¸ëœì­ì…˜ |

---

## 5) ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ìƒ¤ë”©

### ìˆ˜ë™ ìƒ¤ë”© ì „ëµ

Citus ì—†ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ **ë…¼ë¦¬ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì‚°**í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

#### í•´ì‹œ ê¸°ë°˜ ìƒ¤ë”©
```python
import psycopg2
import hashlib

# ìƒ¤ë“œ ì„¤ì • (3ê°œ ìƒ¤ë“œ)
SHARDS = [
    {"host": "shard1.db.example.com", "port": 5432},
    {"host": "shard2.db.example.com", "port": 5432},
    {"host": "shard3.db.example.com", "port": 5432},
]

def get_shard_id(user_id, num_shards=3):
    """user_id ê¸°ë°˜ ìƒ¤ë“œ ì„ íƒ"""
    hash_value = int(hashlib.md5(str(user_id).encode()).hexdigest(), 16)
    return hash_value % num_shards

def get_connection(shard_id):
    """ìƒ¤ë“œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
    shard = SHARDS[shard_id]
    return psycopg2.connect(...)

def insert_vector(user_id, content, embedding):
    """ìƒ¤ë“œì— ë²¡í„° ì‚½ì…"""
    shard_id = get_shard_id(user_id)
    conn = get_connection(shard_id)
    
    try:
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO embeddings (user_id, content, embedding)
            VALUES (%s, %s, %s)
        """, (user_id, content, embedding))
        conn.commit()
    finally:
        conn.close()

def search_vector_by_user(user_id, query_vec, top_k=10):
    """íŠ¹ì • ì‚¬ìš©ìì˜ ë²¡í„° ê²€ìƒ‰ (ë‹¨ì¼ ìƒ¤ë“œ)"""
    shard_id = get_shard_id(user_id)
    conn = get_connection(shard_id)
    
    try:
        cur = conn.cursor()
        cur.execute("""
            SELECT id, content, embedding <=> %s::vector(768) AS distance
            FROM embeddings
            WHERE user_id = %s
            ORDER BY distance
            LIMIT %s
        """, (query_vec, user_id, top_k))
        return cur.fetchall()
    finally:
        conn.close()

def search_vector_global(query_vec, top_k=10):
    """ì „ì²´ ìƒ¤ë“œ ê²€ìƒ‰ (ë³‘ë ¬ ì‹¤í–‰)"""
    from concurrent.futures import ThreadPoolExecutor
    
    def search_shard(shard_id):
        conn = get_connection(shard_id)
        try:
            cur = conn.cursor()
            cur.execute("""
                SELECT id, content, embedding <=> %s::vector(768) AS distance
                FROM embeddings
                ORDER BY distance
                LIMIT %s
            """, (query_vec, top_k))
            return cur.fetchall()
        finally:
            conn.close()
    
    # ë³‘ë ¬ë¡œ ëª¨ë“  ìƒ¤ë“œ ê²€ìƒ‰
    with ThreadPoolExecutor(max_workers=len(SHARDS)) as executor:
        shard_results = list(executor.map(search_shard, range(len(SHARDS))))
    
    # ê²°ê³¼ ë³‘í•© ë° ì¬ì •ë ¬
    all_results = []
    for results in shard_results:
        all_results.extend(results)
    
    # ê±°ë¦¬ ê¸°ì¤€ ì •ë ¬
    all_results.sort(key=lambda x: x[2])  # distanceë¡œ ì •ë ¬
    
    return all_results[:top_k]
```

#### ë²”ìœ„ ê¸°ë°˜ ìƒ¤ë”©
```python
def get_shard_by_date(created_at):
    """ë‚ ì§œ ê¸°ë°˜ ìƒ¤ë“œ ì„ íƒ (ì‹œê³„ì—´ ë°ì´í„°)"""
    if created_at >= datetime(2024, 1, 1):
        return 0  # shard1: 2024ë…„ ì´í›„
    elif created_at >= datetime(2023, 1, 1):
        return 1  # shard2: 2023ë…„
    else:
        return 2  # shard3: 2022ë…„ ì´ì „

def search_by_date_range(start_date, end_date, query_vec, top_k=10):
    """ë‚ ì§œ ë²”ìœ„ ê²€ìƒ‰ (í•„ìš”í•œ ìƒ¤ë“œë§Œ ì¡°íšŒ)"""
    # í•„ìš”í•œ ìƒ¤ë“œ ì‹ë³„
    shard_ids = set()
    for date in [start_date, end_date]:
        shard_ids.add(get_shard_by_date(date))
    
    # í•´ë‹¹ ìƒ¤ë“œë§Œ ê²€ìƒ‰
    results = []
    for shard_id in shard_ids:
        conn = get_connection(shard_id)
        cur = conn.cursor()
        cur.execute("""
            SELECT id, content, created_at
            FROM embeddings
            WHERE created_at BETWEEN %s AND %s
            ORDER BY embedding <=> %s::vector(768)
            LIMIT %s
        """, (start_date, end_date, query_vec, top_k))
        results.extend(cur.fetchall())
        conn.close()
    
    return results[:top_k]
```

---

## 6) ìƒ¤ë”© í‚¤ ì„ íƒ ê°€ì´ë“œ

### ì¢‹ì€ ìƒ¤ë”© í‚¤ íŠ¹ì„±

| íŠ¹ì„± | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| **ê³ ë¥´ê²Œ ë¶„ì‚°** | ë°ì´í„°ê°€ ìƒ¤ë“œì— ê· ë“±í•˜ê²Œ ë¶„í¬ | user_id (í•´ì‹œ) |
| **ì¿¼ë¦¬ íŒ¨í„´ ë§ì¶¤** | ëŒ€ë¶€ë¶„ì˜ ì¿¼ë¦¬ê°€ ë‹¨ì¼ ìƒ¤ë“œë§Œ ì ‘ê·¼ | tenant_id (ë©€í‹°í…Œë„ŒíŠ¸) |
| **ë¶ˆë³€ì„±** | ê°’ì´ ë³€í•˜ì§€ ì•ŠìŒ | user_id âœ…, status âŒ |
| **ì¹´ë””ë„ë¦¬í‹° ë†’ìŒ** | ê³ ìœ ê°’ì´ ë§ìŒ | user_id âœ…, gender âŒ |

### ìƒ¤ë”© í‚¤ ì„ íƒ ì˜ˆì‹œ

#### SaaS ì• í”Œë¦¬ì¼€ì´ì…˜ (ë©€í‹°í…Œë„ŒíŠ¸)
```sql
-- tenant_id ê¸°ì¤€ ìƒ¤ë”©
SELECT create_distributed_table('embeddings', 'tenant_id');

-- ëŒ€ë¶€ë¶„ì˜ ì¿¼ë¦¬ê°€ ë‹¨ì¼ ìƒ¤ë“œë§Œ ì ‘ê·¼
SELECT * FROM embeddings
WHERE tenant_id = 'company_123'
ORDER BY embedding <=> '[...]';
```

#### ì†Œì…œ ë„¤íŠ¸ì›Œí¬
```sql
-- user_id ê¸°ì¤€ ìƒ¤ë”©
SELECT create_distributed_table('user_posts', 'user_id');

-- íŠ¹ì • ì‚¬ìš©ìì˜ ê²Œì‹œë¬¼ ê²€ìƒ‰ (ë‹¨ì¼ ìƒ¤ë“œ)
SELECT * FROM user_posts
WHERE user_id = 12345
ORDER BY embedding <=> '[...]';
```

#### ì‹œê³„ì—´ ë°ì´í„°
```python
# ë‚ ì§œ ê¸°ì¤€ ìƒ¤ë”© (ì›”ë³„)
def get_shard_by_month(date):
    return date.strftime("%Y%m")  # "202401", "202402" ...

# ìµœê·¼ 3ê°œì›” ê²€ìƒ‰ (3ê°œ ìƒ¤ë“œë§Œ ì ‘ê·¼)
shards = ["202411", "202412", "202501"]
```

---

## 7) ìŠ¤ì¼€ì¼ë§ ì „ëµ ì„ íƒ ê°€ì´ë“œ

### ë°ì´í„° ê·œëª¨ë³„ ê¶Œì¥ ì „ëµ

| ë°ì´í„° ê·œëª¨ | ê¶Œì¥ ì „ëµ | ì˜ˆìƒ ë¹„ìš© | ë³µì¡ë„ |
|------------|----------|----------|--------|
| **~100ë§Œ** | Vertical (16GB RAM) | $ | ë‚®ìŒ |
| **~1ì²œë§Œ** | Vertical (64GB RAM) + Replica | $$ | ì¤‘ê°„ |
| **~1ì–µ** | Vertical (128GB RAM) + Replica + íŒŒí‹°ì…”ë‹ | $$$ | ì¤‘ê°„ |
| **1ì–µ~10ì–µ** | Sharding (Citus or ìˆ˜ë™) | $$$$ | ë†’ìŒ |
| **10ì–µ+** | ì „ë¬¸ ë²¡í„° DB ê³ ë ¤ (Pinecone, Milvus) | $$$$$ | ë†’ìŒ |

### ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸
```
ë°ì´í„° < 1ì²œë§Œ?
â”œâ”€ Yes â†’ Vertical Scaling
â””â”€ No â†’ ì½ê¸° ë¶€í•˜ ë†’ìŒ?
         â”œâ”€ Yes â†’ Replica êµ¬ì„±
         â””â”€ No â†’ ë°ì´í„° > 1ì–µ?
                  â”œâ”€ Yes â†’ Sharding
                  â””â”€ No â†’ Vertical + Replica
```

---

## 8) ì‹¤ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‚¬ë¡€

### ì‚¬ë¡€: ë‹¨ì¼ ì„œë²„ â†’ Sharding (1ì–µ â†’ 10ì–µ ë²¡í„°)

**ì´ˆê¸° ìƒíƒœ:**
- ë‹¨ì¼ ì„œë²„: 128GB RAM, 32 cores
- ë°ì´í„°: 1ì–µ ë²¡í„° (768ì°¨ì›)
- ê²€ìƒ‰ ì‹œê°„: P95 150ms
- ë¹„ìš©: $800/ì›”

**ë¬¸ì œ:**
- ë°ì´í„° 10ì–µìœ¼ë¡œ ì¦ê°€ ì˜ˆìƒ
- ë‹¨ì¼ ì„œë²„ í•œê³„ ë„ë‹¬
- ê²€ìƒ‰ ì†ë„ ì €í•˜

**í•´ê²° (Citus 3-ìƒ¤ë“œ êµ¬ì„±):**
```sql
-- 1) Citus ì„¤ì •
CREATE EXTENSION citus;
SELECT citus_add_node('worker1', 5432);
SELECT citus_add_node('worker2', 5432);
SELECT citus_add_node('worker3', 5432);

-- 2) ë¶„ì‚° í…Œì´ë¸” ìƒì„±
CREATE TABLE embeddings_distributed (
    id BIGSERIAL,
    user_id BIGINT,
    content TEXT,
    embedding VECTOR(768),
    created_at TIMESTAMP DEFAULT NOW()
);

SELECT create_distributed_table('embeddings_distributed', 'user_id');

-- 3) ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ (ê¸°ì¡´ â†’ ë¶„ì‚°)
INSERT INTO embeddings_distributed
SELECT * FROM embeddings;

-- 4) ì¸ë±ìŠ¤ ìƒì„± (ê° ìƒ¤ë“œë³„)
CREATE INDEX idx_embedding_shard ON embeddings_distributed
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**ê²°ê³¼:**
- ë°ì´í„°: 10ì–µ ë²¡í„° ì²˜ë¦¬ ê°€ëŠ¥
- ê²€ìƒ‰ ì‹œê°„: P95 80ms (1.9ë°° í–¥ìƒ)
- ë³‘ë ¬ ì²˜ë¦¬: 3ë°° ì²˜ë¦¬ëŸ‰ ì¦ê°€
- ë¹„ìš©: $1,200/ì›” (3 workers Ã— $400)

---

## 9) ê³ ê°€ìš©ì„± (High Availability)

### Patroni + HAProxy êµ¬ì„±

ê³ ê°€ìš©ì„±ì„ ìœ„í•œ ìë™ ì¥ì• ì¡°ì¹˜(Failover) êµ¬ì„±ì…ë‹ˆë‹¤.
```yaml
# docker-compose.yml
version: '3.8'

services:
  etcd:
    image: quay.io/coreos/etcd:latest
    environment:
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379

  haproxy:
    image: haproxy:latest
    ports:
      - "5000:5000"  # Master (write)
      - "5001:5001"  # Replica (read)
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg

  patroni1:
    image: patroni:latest
    environment:
      PATRONI_NAME: patroni1
      PATRONI_ETCD_HOSTS: etcd:2379

  patroni2:
    image: patroni:latest
    environment:
      PATRONI_NAME: patroni2
      PATRONI_ETCD_HOSTS: etcd:2379
```
```python
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ê²° (HAProxy í†µí•´)
write_conn = psycopg2.connect(...)

read_conn = psycopg2.connect(...)
```

---

## 10) ìš”ì•½

### í•µì‹¬ í¬ì¸íŠ¸

1. **Vertical Scaling**  
   ë‹¨ì¼ ì„œë²„ ì„±ëŠ¥ í–¥ìƒ, 1ì²œë§Œ ê±´ê¹Œì§€ íš¨ê³¼ì 

2. **Replication**  
   ì½ê¸° ë¶€í•˜ ë¶„ì‚°, ê³ ê°€ìš©ì„± í™•ë³´, ì“°ê¸°ëŠ” Masterë§Œ

3. **Sharding**  
   ë°ì´í„° ë¶„ì‚°, 1ì–µ ê±´ ì´ìƒì—ì„œ í•„ìˆ˜, Citus ë˜ëŠ” ìˆ˜ë™ êµ¬í˜„

4. **ìƒ¤ë”© í‚¤ ì„ íƒ**  
   ê³ ë¥´ê²Œ ë¶„ì‚° + ì¿¼ë¦¬ íŒ¨í„´ ë§ì¶¤ + ë¶ˆë³€ì„±

5. **ìŠ¤ì¼€ì¼ë§ ìˆœì„œ**  
   Vertical â†’ Replica â†’ Sharding

### í™•ì¥ ì „ëµ ìš”ì•½

| ë‹¨ê³„ | ë°ì´í„° ê·œëª¨ | ì „ëµ | ì„œë²„ ìˆ˜ | ë¹„ìš© |
|------|------------|------|---------|------|
| 1 | ~1ì²œë§Œ | Vertical (64GB) | 1 | $ |
| 2 | ~5ì²œë§Œ | + Replica (2ê°œ) | 3 | $$ |
| 3 | ~1ì–µ | Vertical (128GB) | 3 | $$$ |
| 4 | ~10ì–µ | Sharding (3ìƒ¤ë“œ) | 9 | $$$$ |
| 5 | 10ì–µ+ | ì „ë¬¸ ë²¡í„° DB | - | $$$$$ |

---