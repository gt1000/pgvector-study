# ğŸ“˜ 11. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)

í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(Hybrid Search)ì€ **í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰(BM25)**ê³¼ **ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰**ì„ ê²°í•©í•˜ì—¬  
ê°ê°ì˜ ì¥ì ì„ ì‚´ë¦¬ê³  ë‹¨ì ì„ ë³´ì™„í•˜ëŠ” ìµœì‹  ê²€ìƒ‰ ê¸°ìˆ ì…ë‹ˆë‹¤.

> ğŸ” **í•µì‹¬ ê°œë…:**  
> - **BM25**: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­, ìš©ì–´ ë¹ˆë„ ê¸°ë°˜ ê²€ìƒ‰  
> - **ë²¡í„° ê²€ìƒ‰**: ì˜ë¯¸ ìœ ì‚¬ë„, ë™ì˜ì–´/ìœ ì‚¬ì–´ ì²˜ë¦¬  
> - **í•˜ì´ë¸Œë¦¬ë“œ**: ë‘ ë°©ì‹ì„ ìœµí•©í•˜ì—¬ **ìµœê³ ì˜ ê²€ìƒ‰ í’ˆì§ˆ** ë‹¬ì„±

---

## 1) ì™œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ í•„ìš”í•œê°€?

### ê° ê²€ìƒ‰ ë°©ì‹ì˜ ì¥ë‹¨ì 

| ê²€ìƒ‰ ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì˜ˆì‹œ |
|----------|------|------|------|
| **í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)** | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­<br>ë¹ ë¥¸ ì†ë„<br>ì„¤ëª… ê°€ëŠ¥ì„± ë†’ìŒ | ë™ì˜ì–´ ì²˜ë¦¬ ë¶ˆê°€<br>ë¬¸ë§¥ ì´í•´ ë¶€ì¡± | "PostgreSQL" âœ…<br>"Postgres" âŒ |
| **ë²¡í„° ê²€ìƒ‰** | ì˜ë¯¸ ì´í•´<br>ë™ì˜ì–´/ìœ ì˜ì–´ ì²˜ë¦¬<br>ë¬¸ë§¥ íŒŒì•… | ì •í™•í•œ ìš©ì–´ ëˆ„ë½ ê°€ëŠ¥<br>ì„¤ëª… ì–´ë ¤ì›€ | "ë°ì´í„°ë² ì´ìŠ¤" âœ…<br>"DB" âœ…<br>"PostgreSQL" âš ï¸ |
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | ë‘˜ì˜ ì¥ì  ê²°í•©<br>ìµœê³  ì •í™•ë„ | êµ¬í˜„ ë³µì¡<br>ê³„ì‚° ë¹„ìš© ì¦ê°€ | í‚¤ì›Œë“œ + ì˜ë¯¸ ëª¨ë‘ ë§Œì¡± |

### ì‹¤ì œ ê²€ìƒ‰ ë¹„êµ

**ì§ˆë¬¸:** "PostgreSQLì—ì„œ ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™” ë°©ë²•"

```
[BM25ë§Œ ì‚¬ìš©]
1. "PostgreSQL vector search performance optimization" âœ… (ì™„ë²½ ë§¤ì¹­)
2. "PostgreSQL indexing strategies" âœ… (í‚¤ì›Œë“œ ì¼ì¹˜)
3. "PostgreSQL configuration tuning" âš ï¸ (ì¼ë¶€ ë§¤ì¹­)
   â†’ ì •í™•í•œ ìš©ì–´ëŠ” ì˜ ì°¾ì§€ë§Œ, ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ëˆ„ë½

[ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©]
1. "ë°ì´í„°ë² ì´ìŠ¤ ì„ë² ë”© ìµœì í™” ê¸°ë²•" âœ… (ì˜ë¯¸ ìœ ì‚¬)
2. "Postgres ì¸ë±ìŠ¤ ì„±ëŠ¥ íŠœë‹" âœ… (ë™ì˜ì–´ ì²˜ë¦¬)
3. "ë²¡í„° DB ì†ë„ ê°œì„  ë°©ì•ˆ" âœ… (ê°œë… ì´í•´)
   â†’ ì˜ë¯¸ëŠ” ì˜ íŒŒì•…í•˜ì§€ë§Œ, "PostgreSQL" ëª…ì‹œ ë¬¸ì„œ ëˆ„ë½ ê°€ëŠ¥

[í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰]
1. "PostgreSQL vector search performance optimization" âœ…âœ…
2. "Postgres ë²¡í„° ì¸ë±ìŠ¤ ì„±ëŠ¥ íŠœë‹" âœ…âœ…
3. "PostgreSQL embedding ìµœì í™” ê¸°ë²•" âœ…âœ…
   â†’ ì •í™•í•œ ìš©ì–´ + ì˜ë¯¸ ìœ ì‚¬ë„ ëª¨ë‘ ê³ ë ¤
```

---

## 2) BM25ë€?

### BM25 (Best Matching 25) ê°œìš”

BM25ëŠ” **í™•ë¥  ê¸°ë°˜ ìˆœìœ„í™” í•¨ìˆ˜**ë¡œ, ë¬¸ì„œì˜ í‚¤ì›Œë“œ ë¹ˆë„ì™€ ë¬¸ì„œ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

### BM25 ì ìˆ˜ ê³„ì‚°

$$
\text{BM25}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})}
$$

**íŒŒë¼ë¯¸í„°:**
- `k1`: ìš©ì–´ ë¹ˆë„ í¬í™” íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 1.2)
- `b`: ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™” (ê¸°ë³¸ê°’: 0.75)
- `f(qi, D)`: ë¬¸ì„œ Dì—ì„œ ì¿¼ë¦¬ ìš©ì–´ qiì˜ ë¹ˆë„
- `|D|`: ë¬¸ì„œ ê¸¸ì´
- `avgdl`: ì „ì²´ ë¬¸ì„œì˜ í‰ê·  ê¸¸ì´

> ğŸ’¡ **ê°„ë‹¨íˆ ë§í•˜ë©´:**  
> "ì¿¼ë¦¬ ë‹¨ì–´ê°€ ë¬¸ì„œì— ë§ì´ ë“±ì¥í• ìˆ˜ë¡ + ê·¸ ë‹¨ì–´ê°€ ì „ì²´ ë¬¸ì„œì—ì„œ í¬ê·€í• ìˆ˜ë¡ + ë¬¸ì„œ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬" ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.

### PostgreSQLì—ì„œ BM25 êµ¬í˜„

PostgreSQLì˜ `ts_rank_cd` í•¨ìˆ˜ëŠ” BM25ì™€ ìœ ì‚¬í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```ts_rank_cd
> PostgreSQL `ts_rank_cd` í•¨ìˆ˜

`ts_rank_cd`ëŠ” PostgreSQL ì „ë¬¸ê²€ìƒ‰(Full-Text Search, FTS)ì—ì„œ  
**ë¬¸ì„œê°€ ê²€ìƒ‰ ì§ˆì˜ì™€ ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€(ì í•©ë„)** ë¥¼ ì ìˆ˜ë¡œ ê³„ì‚°í•˜ëŠ” ë­í‚¹ í•¨ìˆ˜ì´ë‹¤.

> í•µì‹¬ ê°œë…
- **Cover Density(CD)** ê¸°ë°˜ ë­í‚¹
- ê²€ìƒ‰ì–´ë“¤ì´ ë¬¸ì„œ ë‚´ì—ì„œ **ì„œë¡œ ê°€ê¹Œì´ ë°€ì§‘í•´ ë“±ì¥í• ìˆ˜ë¡ ì ìˆ˜ ì¦ê°€**
- ë‹¨ì–´ê°€ í©ì–´ì ¸ ìˆìœ¼ë©´ ì ìˆ˜ ê°ì†Œ

> íŠ¹ì§•
- ë‹¨ì–´ **ë¹ˆë„**ë¿ ì•„ë‹ˆë¼ **ìœ„ì¹˜ì™€ ê·¼ì ‘ë„**ë¥¼ ê°•í•˜ê²Œ ë°˜ì˜
- ì—°ì†ëœ ë¬¸ì¥ì´ë‚˜ ì§§ì€ ë¬¸ì„œì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ê²€ìƒ‰ ê²°ê³¼ ì œê³µ
- ë°˜í™˜ ê°’ì€ **0~1 ì‚¬ì´ì˜ ì‹¤ìˆ˜** (ê°’ì´ í´ìˆ˜ë¡ ê´€ë ¨ë„ ë†’ìŒ)

> `ts_rank`ì™€ì˜ ì°¨ì´
- `ts_rank` : ë‹¨ì–´ ì¶œí˜„ ë¹ˆë„ ì¤‘ì‹¬
- `ts_rank_cd` : ë‹¨ì–´ **ë°€ì§‘ë„(ë¬¸ë§¥ì  ê°€ê¹Œì›€)** ì¤‘ì‹¬

> ì‚¬ìš© ëª©ì 
- ë¬¸ì„œ ê²€ìƒ‰, ì œëª©+ë³¸ë¬¸ ê²€ìƒ‰
- í‚¤ì›Œë“œ ê¸°ë°˜ ì •í™•ë„ ë­í‚¹
- ë²¡í„° ê²€ìƒ‰(pgvector)ê³¼ ê²°í•©í•œ **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¬ì •ë ¬**
```

```sql
-- Full Text Search ì„¤ì •
CREATE TABLE vector.hybrid_docs (
    id BIGSERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    content_tsv TSVECTOR,              -- ì „ë¬¸ ê²€ìƒ‰ìš©(postgresql ë‚´ì¥ íƒ€ì…, í•œêµ­ì–´ëŠ” ë³„ë„ í™•ì¥/êµ¬ì„±ì´ í•„ìš”)
    embedding VECTOR(768)              -- ë²¡í„° ê²€ìƒ‰ìš©
);

-- tsvector ìƒì„± (í…ìŠ¤íŠ¸ â†’ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœ)
UPDATE vector.hybrid_docs
SET content_tsv = to_tsvector('english', title || ' ' || content);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_content_tsv ON vector.hybrid_docs USING GIN (content_tsv);
CREATE INDEX idx_embedding ON vector.hybrid_docs USING hnsw (embedding vector_cosine_ops);

-- BM25 ìœ ì‚¬ ê²€ìƒ‰
SELECT 
    id,
    title,
    ts_rank_cd(content_tsv, query) AS bm25_score
FROM vector.hybrid_docs,
     to_tsquery('english', 'postgresql & vector & search') AS query
WHERE content_tsv @@ query
ORDER BY bm25_score DESC
LIMIT 10;
```

---

## 3) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„
### ë°©ë²• 1: BM25 + ë²¡í„° ê²€ìƒ‰ ê²°í•©

ê°€ì¥ ê¸°ë³¸ì ì¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤. í•œê¸€ì€ ë³„ë„ ì„¤ì •ì´ í•„ìš”í•˜ë‹¤.

```sql
-- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ í•©ì‚°)
WITH bm25_results AS (
    SELECT 
        id,
        ts_rank_cd(content_tsv, query) AS bm25_score
    FROM vector.hybrid_docs,
         to_tsquery('english', 'postgresql & vector') AS query
    WHERE content_tsv @@ query
),
vector_results AS (
    SELECT 
        id,
        1 - (embedding <=> '[0.5, 0.3, ...]'::vector(768)) AS vector_score
    FROM vector.hybrid_docs
)
SELECT 
    COALESCE(b.id, v.id) AS id,
    COALESCE(b.bm25_score, 0) * 0.3 +     -- BM25 ê°€ì¤‘ì¹˜ 30%
    COALESCE(v.vector_score, 0) * 0.7     -- ë²¡í„° ê°€ì¤‘ì¹˜ 70%
    AS hybrid_score
FROM bm25_results b
FULL OUTER JOIN vector_results v ON b.id = v.id
ORDER BY hybrid_score DESC
LIMIT 10;
```

### ë°©ë²• 2: Pythonì—ì„œ ê°€ì¤‘ì¹˜ ì¡°ì •

```python
import psycopg2
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("nomic-ai/nomic-embed-text-v1.5")

def hybrid_search(query_text, alpha=0.7, top_k=10):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    
    Args:
        query_text: ê²€ìƒ‰ ì¿¼ë¦¬
        alpha: ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0~1, BM25ëŠ” 1-alpha)
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    # 1) ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(query_text).tolist()
    
    # 2) ì¿¼ë¦¬ ì „ì²˜ë¦¬ (BM25ìš©)
    # ì˜ˆ: "postgresql vector search" â†’ "postgresql & vector & search"
    query_terms = ' & '.join(query_text.lower().split())
    
    conn = psycopg2.connect(...)
    cur = conn.cursor()
    
    # 3) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
    cur.execute("""
        WITH bm25_results AS (
            SELECT 
                id,
                title,
                content,
                ts_rank_cd(content_tsv, query) AS bm25_score
            FROM vector.hybrid_docs,
                 to_tsquery('english', %s) AS query
            WHERE content_tsv @@ query
        ),
        vector_results AS (
            SELECT 
                id,
                1 - (embedding <=> %s::vector(768)) AS vector_score
            FROM vector.hybrid_docs
        )
        SELECT 
            COALESCE(b.id, v.id) AS id,
            COALESCE(b.title, (SELECT title FROM vector.hybrid_docs WHERE id = v.id)) AS title,
            COALESCE(b.content, (SELECT content FROM vector.hybrid_docs WHERE id = v.id)) AS content,
            COALESCE(b.bm25_score, 0) * %s +
            COALESCE(v.vector_score, 0) * %s AS hybrid_score
        FROM bm25_results b
        FULL OUTER JOIN vector_results v ON b.id = v.id
        ORDER BY hybrid_score DESC
        LIMIT %s
    """, (query_terms, query_embedding, 1 - alpha, alpha, top_k))
    
    results = cur.fetchall()
    cur.close()
    conn.close()
    
    return results

# ì‚¬ìš©
results = hybrid_search("PostgreSQL vector search optimization", alpha=0.6)
for rank, (doc_id, title, content, score) in enumerate(results, 1):
    print(f"{rank}. [{score:.4f}] {title}")
```

---

## 4) RRF (Reciprocal Rank Fusion)
### RRFë€?

RRFëŠ” **ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ ìœµí•©**í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ê° ê²°ê³¼ì˜ ìˆœìœ„ ì—­ìˆ˜ë¥¼ í•©ì‚°í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

### RRF ê³µì‹

$$
\text{RRF}(d) = \sum_{r \in R} \frac{1}{k + \text{rank}_r(d)}
$$

**íŒŒë¼ë¯¸í„°:**
- `k`: ìˆœìœ„ ìƒìˆ˜ (ê¸°ë³¸ê°’: 60, ìˆœìœ„ ì°¨ì´ ì™„í™”)
- `rankáµ£(d)`: ê²€ìƒ‰ ë°©ë²• rì—ì„œ ë¬¸ì„œ dì˜ ìˆœìœ„

### RRFì˜ ì¥ì 

âœ… **ê°„ë‹¨í•¨:** ì ìˆ˜ ì •ê·œí™” ë¶ˆí•„ìš”  
âœ… **ì•ˆì •ì„±:** í•œ ë°©ë²•ì˜ ì´ìƒê°’ì— ëœ ë¯¼ê°  
âœ… **í™•ì¥ì„±:** 3ê°œ ì´ìƒì˜ ê²€ìƒ‰ ë°©ë²•ë„ ì‰½ê²Œ ê²°í•©  
âœ… **íš¨ê³¼ì :** ê°€ì¤‘ì¹˜ íŠœë‹ ì—†ì´ë„ ì¢‹ì€ ì„±ëŠ¥

### RRF êµ¬í˜„

```sql
-- RRF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
WITH bm25_ranked AS (
    SELECT 
        id,
        title,
        ROW_NUMBER() OVER (ORDER BY ts_rank_cd(content_tsv, query) DESC) AS rank
    FROM vector.hybrid_docs,
         to_tsquery('english', 'postgresql & vector') AS query
    WHERE content_tsv @@ query
),
vector_ranked AS (
    SELECT 
        id,
        ROW_NUMBER() OVER (ORDER BY embedding <=> '[...]'::vector(768)) AS rank
    FROM vector.hybrid_docs
)
SELECT 
    COALESCE(b.id, v.id) AS id,
    COALESCE(b.title, (SELECT title FROM vector.hybrid_docs WHERE id = v.id)) AS title,
    (1.0 / (60 + COALESCE(b.rank, 1000))) +    -- BM25 RRF
    (1.0 / (60 + COALESCE(v.rank, 1000)))      -- Vector RRF
    AS rrf_score
FROM bm25_ranked b
FULL OUTER JOIN vector_ranked v ON b.id = v.id
ORDER BY rrf_score DESC
LIMIT 10;
```

### Python RRF êµ¬í˜„

```python
def rrf_hybrid_search(query_text, k=60, top_k=10):
    """
    RRF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    
    Args:
        query_text: ê²€ìƒ‰ ì¿¼ë¦¬
        k: RRF ìƒìˆ˜ (ê¸°ë³¸ê°’: 60)
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    """
    query_embedding = model.encode(query_text).tolist()
    query_terms = ' & '.join(query_text.lower().split())
    
    conn = psycopg2.connect(...)
    cur = conn.cursor()
    
    cur.execute("""
        WITH bm25_ranked AS (
            SELECT 
                id,
                title,
                content,
                ROW_NUMBER() OVER (
                    ORDER BY ts_rank_cd(content_tsv, query) DESC
                ) AS rank
            FROM vector.hybrid_docs,
                 to_tsquery('english', %s) AS query
            WHERE content_tsv @@ query
        ),
        vector_ranked AS (
            SELECT 
                id,
                ROW_NUMBER() OVER (
                    ORDER BY embedding <=> %s::vector(768)
                ) AS rank
            FROM vector.hybrid_docs
        )
        SELECT 
            COALESCE(b.id, v.id) AS id,
            COALESCE(b.title, (SELECT title FROM vector.hybrid_docs WHERE id = v.id)) AS title,
            COALESCE(b.content, (SELECT content FROM vector.hybrid_docs WHERE id = v.id)) AS content,
            (1.0 / (%s + COALESCE(b.rank, 1000))) +
            (1.0 / (%s + COALESCE(v.rank, 1000))) AS rrf_score
        FROM bm25_ranked b
        FULL OUTER JOIN vector_ranked v ON b.id = v.id
        ORDER BY rrf_score DESC
        LIMIT %s
    """, (query_terms, query_embedding, k, k, top_k))
    
    results = cur.fetchall()
    cur.close()
    conn.close()
    
    return results

# ì‚¬ìš©
results = rrf_hybrid_search("vector database performance", k=60)
```

---

## 5) Cross Encoder ê¸°ë°˜ ì¬ë­í‚¹

### Cross Encoderë€?

Cross EncoderëŠ” **ì¿¼ë¦¬ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜** ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ê´€ë ¨ì„±ì„ ì§ì ‘ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.  
ë²¡í„° ê²€ìƒ‰(Bi-Encoder)ë³´ë‹¤ **í›¨ì”¬ ì •í™•í•˜ì§€ë§Œ ëŠë¦½ë‹ˆë‹¤**.

### Bi-Encoder vs Cross Encoder

| êµ¬ë¶„ | Bi-Encoder (ë²¡í„° ê²€ìƒ‰) | Cross Encoder |
|------|----------------------|--------------|
| **êµ¬ì¡°** | ì¿¼ë¦¬/ë¬¸ì„œ ê°ê° ì„ë² ë”© ìƒì„± | ì¿¼ë¦¬+ë¬¸ì„œ ë™ì‹œ ì…ë ¥ |
| **ì†ë„** | ë§¤ìš° ë¹ ë¦„ (ì‚¬ì „ ê³„ì‚°) | ëŠë¦¼ (ì‹¤ì‹œê°„ ê³„ì‚°) |
| **ì •í™•ë„** | ì¤‘ê°„ | ë§¤ìš° ë†’ìŒ |
| **ìš©ë„** | ëŒ€ê·œëª¨ 1ì°¨ ê²€ìƒ‰ | ì†Œê·œëª¨ ì¬ë­í‚¹ |
| **ê³„ì‚° ë¹„ìš©** | O(n) | O(n Ã— m) |

### ì¬ë­í‚¹ íŒŒì´í”„ë¼ì¸

```
[1ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰]
  BM25 + Vector â†’ ìƒìœ„ 100ê°œ í›„ë³´ ì¶”ì¶œ (0.05ì´ˆ)
  
[2ë‹¨ê³„: Cross Encoder ì¬ë­í‚¹]
  100ê°œ í›„ë³´ â†’ ì •ë°€ ì ìˆ˜ ì¬ê³„ì‚° â†’ ìµœì¢… 10ê°œ (0.5ì´ˆ)
  
ì´ ì‹œê°„: 0.55ì´ˆ
ì •í™•ë„: ìµœê³  ìˆ˜ì¤€ (95%+)
```

### Python êµ¬í˜„

```python
from sentence_transformers import CrossEncoder

# 1) Cross Encoder ëª¨ë¸ ë¡œë“œ
cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

def hybrid_search_with_reranking(query_text, top_k=10, candidate_size=100):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Cross Encoder ì¬ë­í‚¹
    
    Args:
        query_text: ê²€ìƒ‰ ì¿¼ë¦¬
        top_k: ìµœì¢… ë°˜í™˜ ê²°ê³¼ ìˆ˜
        candidate_size: ì¬ë­í‚¹ ëŒ€ìƒ í›„ë³´ ìˆ˜
    """
    # 1) 1ì°¨ ê²€ìƒ‰: RRF í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ 100ê°œ í›„ë³´ ì¶”ì¶œ
    candidates = rrf_hybrid_search(query_text, top_k=candidate_size)
    
    # 2) 2ì°¨ ì¬ë­í‚¹: Cross Encoderë¡œ ì •ë°€ ì ìˆ˜ ê³„ì‚°
    query_doc_pairs = [(query_text, content) for _, _, content, _ in candidates]
    cross_scores = cross_encoder.predict(query_doc_pairs)
    
    # 3) ì¬ë­í‚¹ëœ ê²°ê³¼ ìƒì„±
    reranked = []
    for (doc_id, title, content, _), cross_score in zip(candidates, cross_scores):
        reranked.append((doc_id, title, content, float(cross_score)))
    
    # 4) Cross Encoder ì ìˆ˜ë¡œ ì¬ì •ë ¬
    reranked.sort(key=lambda x: x[3], reverse=True)
    
    return reranked[:top_k]

# ì‚¬ìš©
results = hybrid_search_with_reranking("PostgreSQL vector indexing", top_k=5)
for rank, (doc_id, title, content, score) in enumerate(results, 1):
    print(f"{rank}. [{score:.4f}] {title}")
    print(f"   {content[:100]}...")
```

### ë‹¨ê³„ë³„ ì„±ëŠ¥ ë¹„êµ

```python
import time

query = "PostgreSQL vector search performance optimization"

# 1) BM25ë§Œ
start = time.time()
bm25_results = bm25_search(query, top_k=10)
print(f"BM25 only: {time.time() - start:.3f}s")

# 2) ë²¡í„°ë§Œ
start = time.time()
vector_results = vector_search(query, top_k=10)
print(f"Vector only: {time.time() - start:.3f}s")

# 3) í•˜ì´ë¸Œë¦¬ë“œ (RRF)
start = time.time()
hybrid_results = rrf_hybrid_search(query, top_k=10)
print(f"Hybrid (RRF): {time.time() - start:.3f}s")

# 4) í•˜ì´ë¸Œë¦¬ë“œ + ì¬ë­í‚¹
start = time.time()
reranked_results = hybrid_search_with_reranking(query, top_k=10)
print(f"Hybrid + Rerank: {time.time() - start:.3f}s")

# ê²°ê³¼ ì˜ˆì‹œ:
# BM25 only: 0.012s          (ë¹ ë¥´ì§€ë§Œ ì˜ë¯¸ ì´í•´ ë¶€ì¡±)
# Vector only: 0.018s        (ì˜ë¯¸ëŠ” ì¢‹ì§€ë§Œ ì •í™•í•œ ìš©ì–´ ëˆ„ë½)
# Hybrid (RRF): 0.025s       (ê· í˜• ì¡íŒ ê²°ê³¼)
# Hybrid + Rerank: 0.550s    (ìµœê³  ì •í™•ë„, ëŠë¦¼)
```

---

## 6) ì‹¤ì „ êµ¬í˜„: ë…¼ë¬¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ

### ì‹œë‚˜ë¦¬ì˜¤
- 100ë§Œ ê°œì˜ ë…¼ë¬¸ ì´ˆë¡
- ì‚¬ìš©ì ì¿¼ë¦¬: "deep learning for image classification"
- ìš”êµ¬ì‚¬í•­: ì •í™•ë„ ìµœìš°ì„ , ê²€ìƒ‰ ì‹œê°„ < 1ì´ˆ

### ì „ì²´ êµ¬í˜„

```python
from sentence_transformers import SentenceTransformer, CrossEncoder
import psycopg2
import time

# ëª¨ë¸ ë¡œë“œ
bi_encoder = SentenceTransformer("nomic-ai/nomic-embed-text-v1.5")
cross_encoder = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")

class PaperSearchEngine:
    def __init__(self):
        self.conn = psycopg2.connect(...)
    
    def search(self, query_text, alpha=0.6, k=60, rerank_size=100, top_k=10):
        """
        3ë‹¨ê³„ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸
        
        1) BM25 + ë²¡í„° ê²€ìƒ‰ (RRF) â†’ 100ê°œ í›„ë³´
        2) Cross Encoder ì¬ë­í‚¹ â†’ ìµœì¢… 10ê°œ
        """
        start_time = time.time()
        
        # 1) ì¿¼ë¦¬ ì¤€ë¹„
        query_embedding = bi_encoder.encode(query_text).tolist()
        query_terms = ' & '.join(query_text.lower().split())
        
        # 2) 1ì°¨ ê²€ìƒ‰: RRF í•˜ì´ë¸Œë¦¬ë“œ
        cur = self.conn.cursor()
        cur.execute("""
            WITH bm25_ranked AS (
                SELECT 
                    id, title, abstract,
                    ROW_NUMBER() OVER (
                        ORDER BY ts_rank_cd(abstract_tsv, query) DESC
                    ) AS rank
                FROM vector.papers,
                     to_tsquery('english', %s) AS query
                WHERE abstract_tsv @@ query
                LIMIT 1000
            ),
            vector_ranked AS (
                SELECT 
                    id,
                    ROW_NUMBER() OVER (
                        ORDER BY embedding <=> %s::vector(768)
                    ) AS rank
                FROM vector.papers
                LIMIT 1000
            )
            SELECT 
                COALESCE(b.id, v.id) AS id,
                COALESCE(b.title, (SELECT title FROM vector.papers WHERE id = v.id)) AS title,
                COALESCE(b.abstract, (SELECT abstract FROM vector.papers WHERE id = v.id)) AS abstract,
                (1.0 / (%s + COALESCE(b.rank, 2000))) +
                (1.0 / (%s + COALESCE(v.rank, 2000))) AS rrf_score
            FROM bm25_ranked b
            FULL OUTER JOIN vector_ranked v ON b.id = v.id
            ORDER BY rrf_score DESC
            LIMIT %s
        """, (query_terms, query_embedding, k, k, rerank_size))
        
        candidates = cur.fetchall()
        
        stage1_time = time.time() - start_time
        print(f"Stage 1 (Hybrid): {stage1_time:.3f}s - {len(candidates)} candidates")
        
        # 3) 2ì°¨ ì¬ë­í‚¹: Cross Encoder
        query_doc_pairs = [(query_text, abstract) for _, _, abstract, _ in candidates]
        cross_scores = cross_encoder.predict(query_doc_pairs)
        
        reranked = []
        for (doc_id, title, abstract, _), cross_score in zip(candidates, cross_scores):
            reranked.append({
                'id': doc_id,
                'title': title,
                'abstract': abstract,
                'score': float(cross_score)
            })
        
        reranked.sort(key=lambda x: x['score'], reverse=True)
        
        total_time = time.time() - start_time
        print(f"Stage 2 (Rerank): {total_time - stage1_time:.3f}s")
        print(f"Total: {total_time:.3f}s")
        
        cur.close()
        return reranked[:top_k]

# ì‚¬ìš©
engine = PaperSearchEngine()
results = engine.search("deep learning for image classification", top_k=5)

print("\n=== Top 5 Results ===")
for rank, paper in enumerate(results, 1):
    print(f"\n{rank}. [{paper['score']:.4f}] {paper['title']}")
    print(f"   {paper['abstract'][:150]}...")
```

### ì¶œë ¥ ì˜ˆì‹œ

```
Stage 1 (Hybrid): 0.045s - 100 candidates
Stage 2 (Rerank): 0.412s
Total: 0.457s

=== Top 5 Results ===

1. [0.9823] Deep Convolutional Neural Networks for Image Classification
   This paper presents a comprehensive study of deep learning architectures
   for visual recognition tasks, focusing on convolutional neural networks...

2. [0.9654] ResNet: Deep Residual Learning for Image Recognition
   We propose a residual learning framework to ease the training of networks
   that are substantially deeper than those used previously...

3. [0.9521] ImageNet Classification with Deep Convolutional Neural Networks
   We trained a large, deep convolutional neural network to classify the 1.2
   million high-resolution images in the ImageNet LSVRC-2010 contest...
```

---

## 7) ê°€ì¤‘ì¹˜ íŠœë‹ ê°€ì´ë“œ

### Alpha ê°’ (ë²¡í„° ê°€ì¤‘ì¹˜) ì„ íƒ

| Alpha | BM25 ê°€ì¤‘ì¹˜ | ë²¡í„° ê°€ì¤‘ì¹˜ | ì¶”ì²œ ìƒí™© |
|-------|------------|------------|----------|
| 0.3 | 70% | 30% | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ ì¤‘ìš” (ê¸°ìˆ  ë¬¸ì„œ) |
| 0.5 | 50% | 50% | ê· í˜• ì¡íŒ ê²€ìƒ‰ (ì¼ë°˜ ë¬¸ì„œ) |
| 0.7 | 30% | 70% | ì˜ë¯¸ ì´í•´ ì¤‘ìš” (ìì—°ì–´ ì§ˆë¬¸) |
| 0.9 | 10% | 90% | ê±°ì˜ ë²¡í„° ê²€ìƒ‰ (ì¶”ì²œ ì‹œìŠ¤í…œ) |

### RRF k ê°’ ì„ íƒ

| k ê°’ | íš¨ê³¼ | ì¶”ì²œ ìƒí™© |
|------|------|----------|
| 10 | ìƒìœ„ ìˆœìœ„ ê°•ì¡° | ì†Œê·œëª¨ ê²°ê³¼ì…‹ |
| 60 | ê· í˜• (ê¸°ë³¸ê°’) | ì¼ë°˜ì ì¸ ê²½ìš° |
| 100 | í•˜ìœ„ ìˆœìœ„ë„ ê³ ë ¤ | ë‹¤ì–‘ì„± ì¤‘ì‹œ |

### ì‹¤í—˜ ì½”ë“œ

```python
# ê°€ì¤‘ì¹˜ ì‹¤í—˜
test_queries = [
    "PostgreSQL vector search optimization",
    "how to improve database performance",
    "AI model deployment strategies"
]

for alpha in [0.3, 0.5, 0.7, 0.9]:
    print(f"\n=== Alpha = {alpha} ===")
    for query in test_queries:
        results = hybrid_search(query, alpha=alpha, top_k=5)
        print(f"\nQuery: {query}")
        for rank, (_, title, _, score) in enumerate(results, 1):
            print(f"  {rank}. [{score:.4f}] {title[:60]}...")
```

---

## 8) ì„±ëŠ¥ ìµœì í™”

### ì¸ë±ìŠ¤ ìµœì í™”

```sql
-- BM25ìš© GIN ì¸ë±ìŠ¤
CREATE INDEX idx_abstract_tsv ON vector.papers 
USING GIN (abstract_tsv);

-- ë²¡í„°ìš© HNSW ì¸ë±ìŠ¤
CREATE INDEX idx_embedding ON vector.papers 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- í•„í„°ìš© B-tree ì¸ë±ìŠ¤
CREATE INDEX idx_published_date ON vector.papers (published_date);
CREATE INDEX idx_category ON vector.papers (category);
```

### ì¿¼ë¦¬ ìµœì í™”

```sql
-- EXPLAIN ANALYZEë¡œ ì„±ëŠ¥ ë¶„ì„
EXPLAIN (ANALYZE, BUFFERS) 
WITH bm25_ranked AS (...)
...

-- íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
CREATE TABLE vector.papers_2024 PARTITION OF vector.papers
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
```

---

## 9) ì£¼ì˜ì‚¬í•­

### âš ï¸ ì–¸ì–´ë³„ ì „ì²˜ë¦¬

```sql
-- ì˜ì–´
to_tsvector('english', content)

-- í•œêµ­ì–´ (í™•ì¥ í•„ìš”)
-- ë°©ë²• 1: í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš© (mecab, konlpy)
-- ë°©ë²• 2: n-gram ë°©ì‹
```

### âš ï¸ Cross Encoder ë¹„ìš©

Cross EncoderëŠ” ê³„ì‚° ë¹„ìš©ì´ ë†’ìœ¼ë¯€ë¡œ:
- í›„ë³´ í¬ê¸°ë¥¼ 100~200ê°œë¡œ ì œí•œ
- GPUê°€ ìˆë‹¤ë©´ í™œìš© (10ë°° ë¹ ë¦„)
- ìºì‹± ì „ëµ ì‚¬ìš©

```python
# ìºì‹± ì˜ˆì œ
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_rerank(query, doc_id):
    """ìì£¼ ê²€ìƒ‰ë˜ëŠ” ì¿¼ë¦¬-ë¬¸ì„œ ìŒ ìºì‹±"""
    # ì‹¤ì œë¡œëŠ” DBì—ì„œ ë¬¸ì„œ ë¡œë“œ
    doc = get_document(doc_id)
    return cross_encoder.predict([(query, doc)])[0]
```

---

## 10) ìš”ì•½

### í•µì‹¬ í¬ì¸íŠ¸

1. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ = BM25 + ë²¡í„° ê²€ìƒ‰**  
   ê°ê°ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±

2. **RRF (Reciprocal Rank Fusion)**  
   ìˆœìœ„ ê¸°ë°˜ ìœµí•©, ê°€ì¤‘ì¹˜ íŠœë‹ ë¶ˆí•„ìš”, ì•ˆì •ì 

3. **ì¬ë­í‚¹ íŒŒì´í”„ë¼ì¸**  
   1ì°¨: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë¹ ë¦„) â†’ 2ì°¨: Cross Encoder (ì •í™•í•¨)

4. **ì„±ëŠ¥ vs ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„**
    - BM25ë§Œ: 0.01ì´ˆ, ì •í™•ë„ 70%
    - ë²¡í„°ë§Œ: 0.02ì´ˆ, ì •í™•ë„ 75%
    - í•˜ì´ë¸Œë¦¬ë“œ: 0.03ì´ˆ, ì •í™•ë„ 85%
    - í•˜ì´ë¸Œë¦¬ë“œ + ì¬ë­í‚¹: 0.5ì´ˆ, ì •í™•ë„ 95%

5. **ì‹¤ì „ ê¶Œì¥ì‚¬í•­**
    - ì¼ë°˜ ê²€ìƒ‰: RRF í•˜ì´ë¸Œë¦¬ë“œ (alpha=0.5~0.7)
    - ê³ ì •ë°€ ê²€ìƒ‰: í•˜ì´ë¸Œë¦¬ë“œ + Cross Encoder
    - ëŒ€ê·œëª¨: ìºì‹± + GPU í™œìš©

---