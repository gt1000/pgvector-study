# 08. 반정밀도 벡터 (Half-Precision Vectors)

메모리 사용량을 절반으로 줄이는 halfvec 타입 활용법

---

## 1) halfvec 타입 개요

### ① halfvec란?

**halfvec**는 16비트 부동소수점(float16)을 사용하는 벡터 타입입니다.

**기본 비교:**

| 타입 | 비트 수 | 차원당 크기 | 768차원 크기 | 정밀도 |
|------|--------|-----------|------------|--------|
| **vector** | 32bit (float32) | 4 bytes | 3,072 bytes (3KB) | 높음 |
| **halfvec** | 16bit (float16) | 2 bytes | 1,536 bytes (1.5KB) | 중간 |
| **bit** | 1bit | 0.125 bytes | 96 bytes | 낮음 |

**핵심 장점:**
- 저장 공간: **50% 절약** ✅
- 메모리 사용량: **50% 감소** ✅
- 인덱스 크기: **50% 감소** ✅
- 검색 속도: 약간 빠름 (데이터 전송량 감소)

**단점:**
- 정확도: 95~99% (2~5% 감소)
- 값 범위 제한: ±65,504

---

### ② 언제 사용하나?

```
✅ 권장 상황:
- 10만 건 이상 대용량 벡터
- 메모리/디스크 공간 제약
- 95% 정확도로 충분한 경우
- RAG 시스템 (일반적)

❌ 비권장 상황:
- 1만 건 미만 (효과 미미)
- 매우 높은 정확도 필요 (과학 계산)
- 극단적인 값 범위 (정규화 안됨)
```

---

### ③ float16 정밀도 이해

**표현 범위:**
```
float32 (vector):
- 범위: ±3.4 × 10³⁸
- 정밀도: 약 7자리 (소수점)
- 예시: 0.123456789

float16 (halfvec):
- 범위: ±65,504
- 정밀도: 약 3자리 (소수점)
- 예시: 0.1235 (자동 반올림)
```

**실제 변환 예시:**

```python
import numpy as np

# float32 → float16 변환
values_f32 = np.array([0.123456789, -0.987654321, 42.123456], dtype=np.float32)
values_f16 = values_f32.astype(np.float16)

print("float32:", values_f32)
# [0.12345679 -0.98765433 42.123456]

print("float16:", values_f16)
# [0.1235 -0.9873 42.125]
```

**임베딩 벡터는 안전:**
- 대부분 -1 ~ 1 범위로 정규화됨
- 정밀도 3자리면 충분
- 값 범위 초과 가능성 없음

---

## 2) halfvec 테이블 생성

### ① 기본 테이블

```sql
-- halfvec 타입 컬럼
CREATE TABLE paper_chunks_half (
    id BIGSERIAL PRIMARY KEY,
    paper_id TEXT NOT NULL,
    chunk_index INT NOT NULL,
    chunk_text TEXT NOT NULL,
    embedding halfvec(768) NOT NULL,  -- halfvec 사용
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(paper_id, chunk_index)
);
```

**vector vs halfvec 비교:**

```sql
-- vector (float32)
CREATE TABLE docs_full (
    id BIGSERIAL PRIMARY KEY,
    embedding vector(768) NOT NULL  -- 3KB per row
);

-- halfvec (float16)
CREATE TABLE docs_half (
    id BIGSERIAL PRIMARY KEY,
    embedding halfvec(768) NOT NULL  -- 1.5KB per row
);
```

---

### ② 저장 공간 비교

**1백만 행 기준:**

| 타입 | 행당 크기 | 총 크기 | 절약 |
|------|----------|---------|------|
| vector(768) | 3KB | 3GB | - |
| **halfvec(768)** | 1.5KB | **1.5GB** | **50%** ✅ |

**실제 계산:**

```sql
-- 테이블 크기 확인
SELECT 
    pg_size_pretty(pg_total_relation_size('paper_chunks_full')) AS full_size,
    pg_size_pretty(pg_total_relation_size('paper_chunks_half')) AS half_size;

-- 예상 결과:
-- full_size: 3.2GB (인덱스 포함)
-- half_size: 1.6GB (인덱스 포함)
```

---

## 3) halfvec 데이터 삽입

### ① 직접 삽입

```sql
-- halfvec 타입으로 직접 삽입
INSERT INTO paper_chunks_half (paper_id, chunk_index, chunk_text, embedding)
VALUES (
    'paper_001',
    0,
    '청크 내용',
    '[0.1, 0.2, 0.3, ...]'::halfvec(768)  -- halfvec로 캐스팅
);
```

---

### ② vector → halfvec 자동 변환

**PostgreSQL이 자동으로 float32 → float16 변환을 처리합니다.**

```sql
-- vector 값을 halfvec 컬럼에 삽입 (자동 변환)
INSERT INTO paper_chunks_half (paper_id, chunk_index, chunk_text, embedding)
VALUES (
    'paper_001',
    0,
    '청크 내용',
    '[0.123456789, -0.987654321, ...]'::vector(768)  -- vector로 생성
);
-- insert 문에서 vector 타입을 넣어도 컬럼이 halfvec 이면 PostgreSQL이 자동으로 halfvec(768)로 변환해서 저장
-- [0.1235, -0.9873, ...] 형태로 저장됨
```

---

### ③ 기존 vector 테이블에서 복사

```sql
-- Step 1: halfvec 테이블 생성
CREATE TABLE paper_chunks_half (
    id BIGSERIAL PRIMARY KEY,
    paper_id TEXT NOT NULL,
    chunk_index INT NOT NULL,
    chunk_text TEXT NOT NULL,
    embedding halfvec(768) NOT NULL,  -- halfvec 타입
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(paper_id, chunk_index)
);

-- Step 2: 기존 데이터 복사 (자동 변환)
INSERT INTO paper_chunks_half (paper_id, chunk_index, chunk_text, embedding, metadata)
SELECT 
    paper_id,
    chunk_index,
    chunk_text,
    embedding::halfvec(768),  -- vector → halfvec 변환
    metadata
FROM paper_chunks_full;

-- 확인
SELECT COUNT(*) FROM paper_chunks_half;
```

---

### ④ Python에서 삽입

**Python 코드는 변경 불필요 - PostgreSQL이 자동 변환**

```python
from sentence_transformers import SentenceTransformer
import psycopg2

model = SentenceTransformer("jhgan/ko-sbert-sts")
conn = psycopg2.connect(
    host="localhost",
    port=35432,
    database="study",
    user="study_postgres",
    password="study_postgres"
)
cur = conn.cursor()

# 임베딩 생성 (float32 numpy array)
text = "논문 청크 내용"
embedding = model.encode(text)  # numpy.ndarray, dtype=float32

# halfvec 테이블에 삽입 (PostgreSQL이 자동 변환)
cur.execute("""
    INSERT INTO paper_chunks_half (paper_id, chunk_index, chunk_text, embedding)
    VALUES (%s, %s, %s, %s)
""", ('paper_001', 0, text, embedding.tolist()))

conn.commit()
```

**핵심:** Python에서는 float32 그대로 전송, PostgreSQL이 halfvec로 자동 변환

---

### ⑤ 대량 삽입 (Batch Insert)

```python
from psycopg2.extras import execute_batch

texts = ["청크1", "청크2", "청크3", ...]  # 수천 개
embeddings = model.encode(texts)  # (N, 768) float32 array

# 데이터 준비
data = [
    ('paper_001', i, text, emb.tolist())
    for i, (text, emb) in enumerate(zip(texts, embeddings))
]

# Batch Insert (1000개씩)
execute_batch(cur, """
    INSERT INTO paper_chunks_half (paper_id, chunk_index, chunk_text, embedding)
    VALUES (%s, %s, %s, %s)
""", data, page_size=1000)

conn.commit()
print(f"{len(data)}개 삽입 완료")
```

---

## 4) halfvec 검색

### ① 기본 검색 (vector와 동일)

**halfvec는 vector와 동일한 연산자를 사용합니다.**

```sql
-- Cosine Distance 검색
SELECT 
    chunk_text,
    embedding <=> '[0.1, 0.2, ...]'::halfvec(768) AS distance
FROM paper_chunks_half
WHERE paper_id = 'paper_001'
ORDER BY distance
LIMIT 10;
```

**지원 연산자:**

| 연산자 | 거리 함수 | halfvec 지원 |
|--------|----------|------------|
| `<=>` | Cosine Distance | ✅ |
| `<->` | L2 Distance | ✅ |
| `<#>` | Inner Product | ✅ |

---

### ② vector ↔ halfvec 자동 변환

**PostgreSQL은 vector와 halfvec 간 자동 변환을 지원합니다.**

```sql
-- vector 쿼리로 halfvec 테이블 검색 (자동 변환)
SELECT chunk_text, embedding <=> '[...]'::vector(768) AS distance
FROM paper_chunks_half
ORDER BY distance LIMIT 10;

-- halfvec 쿼리로 vector 테이블 검색 (자동 변환)
SELECT chunk_text, embedding <=> '[...]'::halfvec(768) AS distance
FROM paper_chunks_full
ORDER BY distance LIMIT 10;

-- 혼합 검색 (두 테이블 조인)
SELECT 
    h.chunk_text AS half_text,
    f.chunk_text AS full_text,
    h.embedding <=> '[...]'::vector(768) AS half_dist,
    f.embedding <=> '[...]'::halfvec(768) AS full_dist
FROM paper_chunks_half h
JOIN paper_chunks_full f ON h.id = f.id
LIMIT 10;
```

---

### ③ Python 검색 (코드 변경 불필요)

```python
# halfvec 테이블 검색
query = "최적 수온은?"
query_embedding = model.encode(query).tolist()  # float32

# vector 쿼리로 halfvec 테이블 검색 (자동 변환)
cur.execute("""
    SELECT chunk_text, embedding <=> %s AS distance
    FROM paper_chunks_half
    WHERE paper_id = %s
    ORDER BY distance
    LIMIT 5
""", (query_embedding, 'paper_001'))

results = cur.fetchall()
for text, dist in results:
    print(f"유사도: {1-dist:.2%}, 내용: {text[:50]}")
```

**핵심:** Python 코드는 vector/halfvec 구분 없이 동일하게 작성

---

## 5) halfvec 인덱싱

### ① halfvec 전용 Operator Class

**halfvec는 전용 operator class를 사용해야 합니다.**

| 검색 연산자 | vector용 | halfvec용 |
|-----------|---------|----------|
| `<=>` Cosine | `vector_cosine_ops` | `halfvec_cosine_ops` ✅ |
| `<->` L2 | `vector_l2_ops` | `halfvec_l2_ops` ✅ |
| `<#>` Inner Product | `vector_ip_ops` | `halfvec_ip_ops` ✅ |

---

### ② HNSW 인덱스 생성

```sql
-- Cosine Distance 인덱스 (가장 많이 사용)
CREATE INDEX idx_half_embedding_cosine
ON paper_chunks_half
USING hnsw (embedding halfvec_cosine_ops)  -- halfvec 전용
WITH (m = 16, ef_construction = 64);

-- L2 Distance 인덱스
CREATE INDEX idx_half_embedding_l2
ON paper_chunks_half
USING hnsw (embedding halfvec_l2_ops)
WITH (m = 16, ef_construction = 64);

-- Inner Product 인덱스
CREATE INDEX idx_half_embedding_ip
ON paper_chunks_half
USING hnsw (embedding halfvec_ip_ops)
WITH (m = 16, ef_construction = 64);
```

---

### ③ IVFFlat 인덱스 (대용량)

```sql
-- IVFFlat 인덱스
CREATE INDEX idx_half_embedding_ivf
ON paper_chunks_half
USING ivfflat (embedding halfvec_cosine_ops)
WITH (lists = 100);
```

---

### ④ 인덱스 크기 비교

**1백만 행 기준 (768차원):**

| 타입 | 데이터 크기 | 인덱스 크기 | 총합 |
|------|-----------|-----------|------|
| vector + HNSW | 3.0GB | 2.0GB | **5.0GB** |
| **halfvec + HNSW** | **1.5GB** | **1.0GB** | **2.5GB** ✅ |

**절약 효과: 50%**

```sql
-- 인덱스 크기 확인
SELECT 
    indexname,
    pg_size_pretty(pg_relation_size(indexname::regclass)) AS size
FROM pg_indexes
WHERE tablename IN ('paper_chunks_full', 'paper_chunks_half')
ORDER BY indexname;
```

---

### ⑤ 검색 성능

```sql
-- 인덱스 사용 확인
EXPLAIN ANALYZE
SELECT chunk_text, embedding <=> '[...]'::halfvec(768) AS distance
FROM paper_chunks_half
ORDER BY distance
LIMIT 10;

-- 결과 예시:
-- Index Scan using idx_half_embedding_cosine
-- Planning Time: 0.5ms
-- Execution Time: 8.2ms (vector는 10.5ms)
```

**halfvec가 약간 빠른 이유:**
- 데이터 전송량 50% 감소
- 캐시 효율 증가
- 메모리 사용량 감소

---

## 6) 성능 및 정확도

### ① 성능 비교 요약

**테스트 환경:** 1백만 행, 768차원, HNSW 인덱스

| 항목 | vector | halfvec | 차이 |
|------|--------|---------|------|
| **저장 공간** | 3.0GB | 1.5GB | 50% 절약 ✅ |
| **인덱스 크기** | 2.0GB | 1.0GB | 50% 절약 ✅ |
| **총 용량** | 5.0GB | 2.5GB | 50% 절약 ✅ |
| **검색 시간** | 10.5ms | 8.2ms | 22% 빠름 ✅ |
| **정확도** | 100% | 97~99% | 1~3% 감소 ⚠️ |

---

### ② 정확도 테스트

```python
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

model = SentenceTransformer("jhgan/ko-sbert-sts")

# 테스트 데이터
texts = ["문서1", "문서2", "문서3", ...]  # 1000개
query = "검색 질의"

# 임베딩 생성
embeddings_f32 = model.encode(texts)  # float32
query_f32 = model.encode(query)

# float16 변환
embeddings_f16 = embeddings_f32.astype(np.float16)
query_f16 = query_f32.astype(np.float16)

# Cosine 유사도 계산
sim_f32 = cosine_similarity([query_f32], embeddings_f32)[0]
sim_f16 = cosine_similarity([query_f16], embeddings_f16)[0]

# Top-10 비교
top10_f32 = set(np.argsort(sim_f32)[-10:])
top10_f16 = set(np.argsort(sim_f16)[-10:])

# 일치율
overlap = len(top10_f32 & top10_f16)
print(f"Top-10 일치: {overlap}/10 = {overlap*10}%")
# 일반적으로 8~10/10 = 80~100%
```

---

### ③ 메모리 사용량

```sql
-- 테이블별 메모리 사용량 확인
SELECT 
    schemaname || '.' || tablename AS table_name,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS data_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - 
                   pg_relation_size(schemaname||'.'||tablename)) AS index_size
FROM pg_tables
WHERE tablename IN ('paper_chunks_full', 'paper_chunks_half')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

**예상 결과 (1백만 행):**

```
table_name              | total_size | data_size | index_size
------------------------|------------|-----------|------------
public.paper_chunks_full| 5.0 GB     | 3.0 GB    | 2.0 GB
public.paper_chunks_half| 2.5 GB     | 1.5 GB    | 1.0 GB
```

---

## 7) 주의사항

### ① 값 범위 제한

```python
# float16 범위: ±65,504
# 초과 시 Infinity로 변환

import numpy as np

values = np.array([70000, -70000, 0.1], dtype=np.float32)
values_half = values.astype(np.float16)

print(values_half)
# [inf -inf 0.1]
```

**해결책:**
- 임베딩 모델은 대부분 -1 ~ 1 범위로 정규화됨
- 문제없음 ✅

---

### ② Operator Class 일치

```sql
-- ❌ 잘못된 예
CREATE INDEX idx_wrong
ON paper_chunks_half
USING hnsw (embedding vector_cosine_ops);  -- vector ops 사용

-- ✅ 올바른 예
CREATE INDEX idx_correct
ON paper_chunks_half
USING hnsw (embedding halfvec_cosine_ops);  -- halfvec ops
```

---

### ③ 정밀도 손실 확인

```
정밀도 손실이 문제되는 경우:
❌ 과학 계산 (높은 정밀도 필수)
❌ 금융 데이터
❌ 매우 작은 차이 비교

정밀도 손실이 허용되는 경우:
✅ 텍스트 검색 (의미 유사도)
✅ 이미지 검색
✅ 추천 시스템
✅ RAG 시스템 (일반적)
```

---

## 8) 선택 가이드

| 상황 | 권장 타입 | 이유 |
|------|----------|------|
| **1만 건 미만** | vector | 효과 미미 |
| **1만 ~ 10만 건** | halfvec | 공간 절약 시작 |
| **10만 ~ 100만 건** | **halfvec** ✅ | 50% 절약 효과 |
| **100만 건 이상** | **halfvec** ✅ | 필수 (비용/성능) |
| **높은 정확도 필요** | vector | 99%+ 정확도 |
| **95% 정확도 충분** | halfvec | 빠르고 효율적 |
| **메모리/디스크 제약** | halfvec | 50% 절약 |

---

## 9) 요약

### ① 핵심 정리

```
halfvec (float16, 16bit):

장점:
✅ 저장 공간 50% 절약
✅ 인덱스 크기 50% 절약
✅ 검색 속도 약간 빠름
✅ 95~99% 정확도 유지

단점:
⚠️ 정밀도 약간 감소 (3자리)
⚠️ 값 범위 제한 (±65,504)

권장:
- 10만 건 이상 데이터
- RAG 시스템 (일반적)
- 메모리/비용 최적화
```