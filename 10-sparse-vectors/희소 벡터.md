# ğŸ“˜ 10. í¬ì†Œ ë²¡í„° (Sparse Vectors)

í¬ì†Œ ë²¡í„°(Sparse Vector)ëŠ” ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0ì´ê³ , **0ì´ ì•„ë‹Œ ê°’ë§Œ ì €ì¥**í•˜ëŠ” íš¨ìœ¨ì ì¸ ë²¡í„° í‘œí˜„ ë°©ì‹ì…ë‹ˆë‹¤.  
ì¼ë°˜ì ì¸ ë°€ì§‘ ë²¡í„°(Dense Vector)ê°€ ëª¨ë“  ì°¨ì›ì˜ ê°’ì„ ì €ì¥í•˜ëŠ” ë°˜ë©´, í¬ì†Œ ë²¡í„°ëŠ” **ì¸ë±ìŠ¤ì™€ ê°’ ìŒ**ë§Œ ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.

> ğŸ” **í•µì‹¬ ê°œë…:**  
> í¬ì†Œ ë²¡í„°ëŠ” **í…ìŠ¤íŠ¸ ê²€ìƒ‰(TF-IDF, BM25)**, **ì¶”ì²œ ì‹œìŠ¤í…œ**, **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.  
> pgvectorì˜ `sparsevec` íƒ€ì…ì€ 0ì´ ì•„ë‹Œ ê°’ë§Œ ì €ì¥í•˜ì—¬ ê³ ì°¨ì› ë²¡í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

---

## 1) í¬ì†Œ ë²¡í„°ë€?

### ë°€ì§‘ ë²¡í„° vs í¬ì†Œ ë²¡í„°

| êµ¬ë¶„ | ë°€ì§‘ ë²¡í„° (Dense Vector) | í¬ì†Œ ë²¡í„° (Sparse Vector) |
|------|-------------------------|--------------------------|
| **ì €ì¥ ë°©ì‹** | ëª¨ë“  ì°¨ì›ì˜ ê°’ ì €ì¥ | 0ì´ ì•„ë‹Œ ê°’ë§Œ ì €ì¥ |
| **í‘œí˜„** | `[0.5, 0, 0, 0.8, 0, 0, ...]` | `{1:0.5, 4:0.8}` |
| **ë©”ëª¨ë¦¬** | ì°¨ì› ìˆ˜ Ã— 4 bytes | 0ì´ ì•„ë‹Œ ê°’ ê°œìˆ˜ Ã— 8 bytes |
| **ìš©ë„** | ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ì„ë² ë”©) | í‚¤ì›Œë“œ ê²€ìƒ‰, ì¶”ì²œ |
| **ì˜ˆì‹œ** | OpenAI embedding (1536ì°¨ì›) | TF-IDF (50,000ì°¨ì›) |

### í¬ì†Œì„±(Sparsity) ì˜ˆì‹œ

```python
# ë°€ì§‘ ë²¡í„° (768ì°¨ì›, ëª¨ë“  ê°’ ì €ì¥)
dense_vec = [0.82, 0.15, 0.0, 0.0, ..., 0.45]  # 768ê°œ float
# ë©”ëª¨ë¦¬: 768 Ã— 4 = 3,072 bytes

# í¬ì†Œ ë²¡í„° (50,000ì°¨ì›, 0ì´ ì•„ë‹Œ ê°’ 50ê°œë§Œ)
sparse_vec = {15: 0.82, 127: 0.15, 49832: 0.45, ...}  # 50ê°œ ìŒ
# ë©”ëª¨ë¦¬: 50 Ã— 8 = 400 bytes

# ë©”ëª¨ë¦¬ ì ˆì•½: 87% ê°ì†Œ (50,000ì°¨ì›ì¸ë°ë„ ë°€ì§‘ 768ì°¨ì›ë³´ë‹¤ ì‘ìŒ!)
```

---

## 2) pgvectorì˜ sparsevec íƒ€ì…

### sparsevec êµ¬ì¡°

pgvectorëŠ” `sparsevec(ì°¨ì›ìˆ˜)` íƒ€ì…ìœ¼ë¡œ í¬ì†Œ ë²¡í„°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

```sql
-- sparsevec ì»¬ëŸ¼ ìƒì„±
CREATE TABLE vector.sparse_embeddings (
    id BIGSERIAL PRIMARY KEY,
    doc_text TEXT,
    sparse_vec SPARSEVEC(50000)  -- 50,000ì°¨ì› í¬ì†Œ ë²¡í„°
);
```

### í‘œí˜„ í˜•ì‹

í¬ì†Œ ë²¡í„°ëŠ” `{ì¸ë±ìŠ¤:ê°’, ì¸ë±ìŠ¤:ê°’, ...}` í˜•íƒœë¡œ í‘œí˜„ë©ë‹ˆë‹¤.

```sql
-- ì˜ˆ: 50,000ì°¨ì› ë²¡í„°ì—ì„œ 3ê°œ ê°’ë§Œ 0ì´ ì•„ë‹˜
-- ì¸ë±ìŠ¤ 1: 0.5
-- ì¸ë±ìŠ¤ 5: 1.0  
-- ì¸ë±ìŠ¤ 9832: 0.3

INSERT INTO vector.sparse_embeddings (doc_text, sparse_vec)
VALUES (
    'PostgreSQL vector search',
    '{1:0.5, 5:1.0, 9832:0.3}/50000'::sparsevec(50000)
);
```

> âš ï¸ **ì£¼ì˜:** ì¸ë±ìŠ¤ëŠ” **1ë¶€í„° ì‹œì‘**í•˜ê³  (0ì´ ì•„ë‹˜!), ë°˜ë“œì‹œ ë’¤ì— /ì „ì²´ì°¨ì›ì„ ë¶™ì—¬ì•¼ í•¨

---

## 3) sparsevec ì‚½ì…

### ë‹¨ì¼ ì‚½ì…

```sql
-- ê¸°ë³¸ ì‚½ì…
INSERT INTO vector.sparse_embeddings (doc_text, sparse_vec)
VALUES (
    'pgvector enables vector similarity search',
    '{1:0.5, 5:1.0, 15:0.8}/50000'::sparsevec(50000)
);

-- ë§ì€ ìš”ì†Œë¥¼ ê°€ì§„ í¬ì†Œ ë²¡í„°
INSERT INTO vector.sparse_embeddings (doc_text, sparse_vec)
VALUES (
    'machine learning and artificial intelligence',
    '{3:0.45, 12:0.67, 89:0.23, 456:0.91, 1203:0.34}/50000'::sparsevec(50000)
);
```

### Pythonì—ì„œ ì‚½ì…

#### ì˜ˆì œ 1: ë”•ì…”ë„ˆë¦¬ â†’ sparsevec

```python
import psycopg2

# í¬ì†Œ ë²¡í„° (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
sparse_dict = {
    1: 0.5,
    5: 1.0,
    15: 0.8,
    234: 0.3
}

# sparsevec ë¬¸ìì—´ ìƒì„±
sparse_str = '{' + ', '.join(f'{k}:{v}' for k, v in sparse_dict.items()) + '}/50000'
# ê²°ê³¼: '{1:0.5, 5:1.0, 15:0.8, 234:0.3}/50000'

conn = psycopg2.connect(...)
    cur = conn.cursor()

cur.execute("""
    INSERT INTO vector.sparse_embeddings (doc_text, sparse_vec)
    VALUES (%s, %s::sparsevec(50000))
""", ('sample document', sparse_str))

conn.commit()
cur.close()
conn.close()
```

#### ì˜ˆì œ 2: TF-IDF â†’ sparsevec

```python
from sklearn.feature_extraction.text import TfidfVectorizer
import psycopg2

# 1) ë¬¸ì„œ ì¤€ë¹„
documents = [
    "pgvector enables vector similarity search in PostgreSQL",
    "sparse vectors are memory efficient for high dimensional data",
    "TF-IDF creates sparse representations of text documents"
]

# 2) TF-IDF ë²¡í„°í™”
vectorizer = TfidfVectorizer(max_features=50000)
tfidf_matrix = vectorizer.fit_transform(documents)

# 3) ì²« ë²ˆì§¸ ë¬¸ì„œì˜ í¬ì†Œ ë²¡í„° ì¶”ì¶œ
doc_vector = tfidf_matrix[0]  # scipy sparse matrix

# 4) sparsevec í˜•ì‹ìœ¼ë¡œ ë³€í™˜
sparse_dict = {}
for idx, value in zip(doc_vector.indices, doc_vector.data):
    # PostgreSQLì€ 1-based index
    sparse_dict[idx + 1] = float(value)

sparse_str = '{' + ', '.join(f'{k}:{v}' for k, v in sparse_dict.items()) + '}/50000'

# 5) PostgreSQL ì €ì¥
conn = psycopg2.connect(...)
cur = conn.cursor()

cur.execute("""
    INSERT INTO vector.sparse_embeddings (doc_text, sparse_vec)
    VALUES (%s, %s::sparsevec(50000))
""", (documents[0], sparse_str))

conn.commit()
```

### ë²Œí¬ ì‚½ì…

```python
import psycopg2
from psycopg2.extras import execute_batch

documents = [
    "document 1 text",
    "document 2 text",
    "document 3 text"
]

# TF-IDF ë²¡í„°í™”
tfidf_matrix = vectorizer.fit_transform(documents)

# ë²Œí¬ ì‚½ì… ë°ì´í„° ì¤€ë¹„
bulk_data = []
for i, doc in enumerate(documents):
    doc_vector = tfidf_matrix[i]
    sparse_dict = {idx + 1: float(val) for idx, val in zip(doc_vector.indices, doc_vector.data)}
    sparse_str = '{' + ', '.join(f'{k}:{v}' for k, v in sparse_dict.items()) + '}/50000'
    bulk_data.append((doc, sparse_str))

conn = psycopg2.connect(...)
cur = conn.cursor()

execute_batch(cur, """
    INSERT INTO vector.sparse_embeddings (doc_text, sparse_vec)
    VALUES (%s, %s::sparsevec(50000))
""", bulk_data, page_size=1000)

conn.commit()
```

---

## 4) sparsevec ê±°ë¦¬ í•¨ìˆ˜

pgvectorëŠ” í¬ì†Œ ë²¡í„° ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ì—¬ëŸ¬ ê±°ë¦¬ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

| ì—°ì‚°ì | ê±°ë¦¬ í•¨ìˆ˜ | ì„¤ëª… | ìš©ë„ |
|--------|----------|------|------|
| `<->` | L2 Distance (Euclidean) | ìœ í´ë¦¬ë“œ ê±°ë¦¬ | ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ |
| `<#>` | Negative Inner Product | ë‚´ì ì˜ ìŒìˆ˜ | ì¶”ì²œ ì‹œìŠ¤í…œ |
| `<=>` | Cosine Distance | ì½”ì‚¬ì¸ ê±°ë¦¬ | í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ |
| `<+>` | L1 Distance (Manhattan) | ë§¨í•´íŠ¼ ê±°ë¦¬ | íŠ¹ìˆ˜ ìš©ë„ |

### ë‚´ì  (Inner Product) - ì¶”ì²œ ì‹œìŠ¤í…œ

í¬ì†Œ ë²¡í„°ëŠ” **ë‚´ì (Inner Product)** ì„ ì‚¬ìš©í•œ ê²€ìƒ‰ì´ ê°€ì¥ íš¨ìœ¨ì ì…ë‹ˆë‹¤.

```sql
-- ë‚´ì  ê¸°ë°˜ ê²€ìƒ‰ (ì¶”ì²œ ì‹œìŠ¤í…œ)
SELECT 
    id,
    doc_text,
    sparse_vec <#> '{1:0.5, 5:1.0, 15:0.8}/50000'::sparsevec(50000) AS neg_inner_product
FROM vector.sparse_embeddings
ORDER BY neg_inner_product  -- ìŒìˆ˜ì´ë¯€ë¡œ ì˜¤ë¦„ì°¨ìˆœ
LIMIT 10;
```

> ğŸ’¡ **ì™œ Negative Inner Product?**  
> pgvectorëŠ” í•­ìƒ "ì‘ì„ìˆ˜ë¡ ìœ ì‚¬"í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  
> ë‚´ì ì€ "í´ìˆ˜ë¡ ìœ ì‚¬"í•˜ë¯€ë¡œ, ìŒìˆ˜ë¥¼ ë¶™ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ - í…ìŠ¤íŠ¸ ê²€ìƒ‰

```sql
-- ì½”ì‚¬ì¸ ê±°ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
SELECT 
    id,
    doc_text,
    sparse_vec <=> '{3:0.45, 12:0.67, 89:0.23}/50000'::sparsevec(50000) AS cosine_distance
FROM vector.sparse_embeddings
ORDER BY cosine_distance
LIMIT 10;
```

---

## 5) sparsevec ê²€ìƒ‰

### ê¸°ë³¸ ê²€ìƒ‰

```sql
-- ì¿¼ë¦¬ í¬ì†Œ ë²¡í„°
-- ì˜ˆ: ì‚¬ìš©ìê°€ "PostgreSQL vector"ë¥¼ ê²€ìƒ‰
-- TF-IDFë¡œ ë³€í™˜ëœ í¬ì†Œ ë²¡í„°: {1:0.5, 5:1.0, 234:0.3}

SELECT 
    id,
    doc_text,
    sparse_vec <#> '{1:0.5, 5:1.0, 234:0.3}/50000'::sparsevec(50000) AS score
FROM vector.sparse_embeddings
ORDER BY score
LIMIT 10;
```

### í•„í„°ë§ê³¼ ê²°í•©

```sql
-- ì¹´í…Œê³ ë¦¬ í•„í„° + í¬ì†Œ ë²¡í„° ê²€ìƒ‰
SELECT 
    id,
    doc_text,
    category,
    sparse_vec <#> :query_vec::sparsevec(50000) AS score
FROM vector.sparse_embeddings
WHERE category = 'technology'
  AND created_at > NOW() - INTERVAL '7 days'
ORDER BY score
LIMIT 20;
```

---

## 6) sparsevec ì¸ë±ì‹±

### í˜„ì¬ ìƒíƒœ (v0.8.1 ê¸°ì¤€)

âš ï¸ **sparsevecëŠ” ì•„ì§ ì¸ë±ìŠ¤ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**  
ëª¨ë“  ê²€ìƒ‰ì€ ìˆœì°¨ ìŠ¤ìº”(Sequential Scan)ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.

```sql
-- âŒ ì—ëŸ¬: sparsevec ì¸ë±ìŠ¤ ë¯¸ì§€ì›
CREATE INDEX idx_sparse ON vector.sparse_embeddings
USING ivfflat (sparse_vec);

-- Error: sparsevec does not support indexing yet
```

### ëŒ€ì•ˆ: í•„í„° ì¸ë±ìŠ¤ í™œìš©

í¬ì†Œ ë²¡í„° ìì²´ëŠ” ì¸ë±ì‹±í•  ìˆ˜ ì—†ì§€ë§Œ, **í•„í„° ì¡°ê±´ì— ì¸ë±ìŠ¤ë¥¼ ìƒì„±**í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì¢í ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```sql
-- í•„í„° ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_category ON vector.sparse_embeddings (category);
CREATE INDEX idx_created_at ON vector.sparse_embeddings (created_at);

-- ì¸ë±ìŠ¤ í™œìš© ê²€ìƒ‰
SELECT id, doc_text, sparse_vec <#> :query_vec AS score
FROM vector.sparse_embeddings
WHERE category = 'AI'  -- ì¸ë±ìŠ¤ ìŠ¤ìº”
ORDER BY score
LIMIT 10;
```

### í–¥í›„ ì „ë§

pgvector ê°œë°œ ë¡œë“œë§µì— ë”°ë¥´ë©´, í–¥í›„ ë²„ì „ì—ì„œ **í¬ì†Œ ë²¡í„° ì¸ë±ì‹±**ì´ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.

---

## 7) ì‹¤ì „ í™œìš© ì‚¬ë¡€

### ì‚¬ë¡€ 1: ì¶”ì²œ ì‹œìŠ¤í…œ

í¬ì†Œ ë²¡í„°ëŠ” **í˜‘ì—… í•„í„°ë§(Collaborative Filtering)** ì¶”ì²œ ì‹œìŠ¤í…œì— ìµœì ì…ë‹ˆë‹¤.

```sql
-- ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© í–‰ë ¬
CREATE TABLE vector.user_interactions (
    user_id BIGINT PRIMARY KEY,
    interaction_vec SPARSEVEC(10000)  -- 10,000ê°œ ì•„ì´í…œ
);

-- ì‚¬ìš©ì ë²¡í„° ì‚½ì…
-- ì˜ˆ: ì‚¬ìš©ì 123ì´ ì•„ì´í…œ 5, 42, 789ì™€ ìƒí˜¸ì‘ìš©
INSERT INTO vector.user_interactions
VALUES (123, '{5:1.0, 42:1.0, 789:1.0}/10000'::sparsevec(10000));

-- ìœ ì‚¬ ì‚¬ìš©ì ì°¾ê¸°
SELECT 
    user_id,
    interaction_vec <#> '{5:1.0, 42:1.0, 789:1.0}/10000'::sparsevec(10000) AS similarity
FROM vector.user_interactions
WHERE user_id != 123
ORDER BY similarity
LIMIT 10;
```

### ì‚¬ë¡€ 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë°€ì§‘ ë²¡í„°)

í¬ì†Œ ë²¡í„°(BM25)ì™€ ë°€ì§‘ ë²¡í„°(ì˜ë¯¸ ê²€ìƒ‰)ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì…ë‹ˆë‹¤.

```sql
-- í•˜ì´ë¸Œë¦¬ë“œ í…Œì´ë¸”
CREATE TABLE vector.hybrid_docs (
    id BIGSERIAL PRIMARY KEY,
    content TEXT,
    sparse_vec SPARSEVEC(50000),   -- BM25
    dense_vec VECTOR(768)           -- ì„ë² ë”©
);

-- RRF (Reciprocal Rank Fusion) ê²€ìƒ‰
WITH sparse_results AS (
    SELECT id, ROW_NUMBER() OVER (ORDER BY sparse_vec <#> :sparse_query) AS rank
    FROM vector.hybrid_docs
    LIMIT 100
),
dense_results AS (
    SELECT id, ROW_NUMBER() OVER (ORDER BY dense_vec <=> :dense_query) AS rank
    FROM vector.hybrid_docs
    LIMIT 100
)
SELECT 
    COALESCE(s.id, d.id) AS id,
    1.0 / (60 + COALESCE(s.rank, 100)) + 
    1.0 / (60 + COALESCE(d.rank, 100)) AS rrf_score
FROM sparse_results s
FULL OUTER JOIN dense_results d ON s.id = d.id
ORDER BY rrf_score DESC
LIMIT 10;
```

---

## 8) í¬ì†Œ ë²¡í„° vs ë°€ì§‘ ë²¡í„°

### ì–¸ì œ í¬ì†Œ ë²¡í„°ë¥¼ ì‚¬ìš©í• ê¹Œ?

| ìƒí™© | ê¶Œì¥ ë²¡í„° íƒ€ì… | ì´ìœ  |
|------|---------------|------|
| **í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰** | í¬ì†Œ ë²¡í„° (TF-IDF, BM25) | ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ |
| **ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰** | ë°€ì§‘ ë²¡í„° (ì„ë² ë”©) | ì˜ë¯¸ ìœ ì‚¬ë„ íŒŒì•… |
| **ì¶”ì²œ ì‹œìŠ¤í…œ** | í¬ì†Œ ë²¡í„° (í˜‘ì—… í•„í„°ë§) | ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© |
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | ë‘˜ ë‹¤ ì‚¬ìš© | ì •í™•ë„ + ì˜ë¯¸ ì´í•´ |
| **50,000ì°¨ì› ì´ìƒ** | í¬ì†Œ ë²¡í„° | ë©”ëª¨ë¦¬ íš¨ìœ¨ |
| **1,000ì°¨ì› ì´í•˜** | ë°€ì§‘ ë²¡í„° | ê°„ë‹¨í•˜ê³  ë¹ ë¦„ |

### ì„±ëŠ¥ ë¹„êµ (100ë§Œ ê°œ ë¬¸ì„œ ê¸°ì¤€)

| í•­ëª© | ë°€ì§‘ ë²¡í„° (768ì°¨ì›) | í¬ì†Œ ë²¡í„° (50,000ì°¨ì›, í‰ê·  50ê°œ ê°’) |
|------|-------------------|-------------------------------------|
| **ë©”ëª¨ë¦¬** | 3GB | 400MB |
| **ê²€ìƒ‰ ì†ë„ (ì¸ë±ìŠ¤ X)** | 150ms | 80ms |
| **ê²€ìƒ‰ ì†ë„ (ì¸ë±ìŠ¤ O)** | 20ms | N/A (ë¯¸ì§€ì›) |
| **ì •í™•ë„ (í‚¤ì›Œë“œ)** | ë‚®ìŒ | ë†’ìŒ |
| **ì •í™•ë„ (ì˜ë¯¸)** | ë†’ìŒ | ë‚®ìŒ |

---

## 9) ì£¼ì˜ì‚¬í•­

### âš ï¸ ì¸ë±ìŠ¤ í˜„ì¬ ë¯¸ì§€ì›

```sql
-- âŒ ì‘ë™í•˜ì§€ ì•ŠìŒ (v0.8.1 ê¸°ì¤€)
CREATE INDEX idx_sparse ON vector.sparse_embeddings
USING ivfflat (sparse_vec);
```

ëŒ€ì•ˆ:
1. í•„í„° ì¡°ê±´ì— ì¸ë±ìŠ¤ ì¶”ê°€
2. ë°ì´í„°ë¥¼ íŒŒí‹°ì…”ë‹í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
3. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼: ë°€ì§‘ ë²¡í„°ë¡œ 1ì°¨ í•„í„°ë§ â†’ í¬ì†Œ ë²¡í„°ë¡œ ì¬ë­í‚¹

### âš ï¸ ì°¨ì› ìˆ˜ ì œí•œ

pgvectorì˜ `sparsevec`ëŠ” ìµœëŒ€ **16,000ì°¨ì›**ê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤ (v0.8.1 ê¸°ì¤€).

```sql
-- âœ… ê°€ëŠ¥
CREATE TABLE ... (vec SPARSEVEC(16000));

-- âŒ ì—ëŸ¬
CREATE TABLE ... (vec SPARSEVEC(20000));
```

### âš ï¸ 1-based ì¸ë±ìŠ¤

í¬ì†Œ ë²¡í„°ì˜ ì¸ë±ìŠ¤ëŠ” **1ë¶€í„° ì‹œì‘**í•©ë‹ˆë‹¤.

```python
# âŒ ì˜ëª»ëœ ì˜ˆ (0-based)
sparse_dict = {0: 0.5, 1: 1.0}  # ì¸ë±ìŠ¤ 0ì€ ì—ëŸ¬

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆ (1-based)
sparse_dict = {1: 0.5, 2: 1.0}
```

---

## 10) Python ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

### í¬ì†Œ ë²¡í„° ë³€í™˜ í—¬í¼

```python
def to_sparsevec(sparse_dict, dim=50000):
    """
    Python dict â†’ PostgreSQL sparsevec ë¬¸ìì—´
    
    Args:
        sparse_dict: {ì¸ë±ìŠ¤: ê°’} ë”•ì…”ë„ˆë¦¬ (1-based)
        dim: ë²¡í„° ì°¨ì› ìˆ˜
    
    Returns:
        sparsevec ë¬¸ìì—´ (ì˜ˆ: '{1:0.5, 5:1.0}')
    """
    if not sparse_dict:
        return '{}'
    
    sparse_str = '{' + ', '.join(f'{k}:{v}' for k, v in sorted(sparse_dict.items())) + '}' + 'ì°¨ì›ê°’'
    return sparse_str

def from_scipy_sparse(scipy_sparse_vec, dim=50000):
    """
    scipy sparse matrix â†’ PostgreSQL sparsevec
    
    Args:
        scipy_sparse_vec: scipy.sparse matrix (1í–‰)
        dim: ë²¡í„° ì°¨ì› ìˆ˜
    
    Returns:
        sparsevec ë¬¸ìì—´
    """
    sparse_dict = {}
    for idx, value in zip(scipy_sparse_vec.indices, scipy_sparse_vec.data):
        sparse_dict[idx + 1] = float(value)  # 1-based index
    
    return to_sparsevec(sparse_dict, dim)

# ì‚¬ìš© ì˜ˆì œ
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=50000)
tfidf_matrix = vectorizer.fit_transform(["sample text"])

sparse_str = from_scipy_sparse(tfidf_matrix[0])
print(sparse_str)  # '{1:0.45, 5:0.67, 123:0.23}/ì°¨ì›ê°’'
```

---

## 11) ìš”ì•½

### í•µì‹¬ í¬ì¸íŠ¸

1. **í¬ì†Œ ë²¡í„° = 0ì´ ì•„ë‹Œ ê°’ë§Œ ì €ì¥**  
   ë©”ëª¨ë¦¬ íš¨ìœ¨ì , ê³ ì°¨ì› ë²¡í„°ì— ìµœì 

2. **sparsevec í˜•ì‹**  
   `{ì¸ë±ìŠ¤:ê°’, ...}` (ì¸ë±ìŠ¤ëŠ” 1ë¶€í„° ì‹œì‘!)

3. **ì£¼ìš” ìš©ë„**
    - í‚¤ì›Œë“œ ê²€ìƒ‰ (TF-IDF, BM25)
    - ì¶”ì²œ ì‹œìŠ¤í…œ (í˜‘ì—… í•„í„°ë§)
    - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í¬ì†Œ + ë°€ì§‘)

4. **ê±°ë¦¬ í•¨ìˆ˜**
    - ë‚´ì  (`<#>`): ì¶”ì²œ ì‹œìŠ¤í…œ
    - ì½”ì‚¬ì¸ (`<=>`): í…ìŠ¤íŠ¸ ìœ ì‚¬ë„

5. **í˜„ì¬ ì œì•½**
    - ì¸ë±ìŠ¤ ë¯¸ì§€ì› (ìˆœì°¨ ìŠ¤ìº”ë§Œ)
    - ìµœëŒ€ 16,000ì°¨ì›
    - í•„í„° ì¸ë±ìŠ¤ë¡œ ì„±ëŠ¥ ë³´ì™„

---