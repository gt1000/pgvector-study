# 📘 03. 임베딩 생성 (Embedding Basics)

임베딩(Embedding)은 텍스트, 이미지, 오디오와 같은 비정형 데이터를 **숫자 벡터 형태로 변환**하여  
AI 모델이 의미 기반 검색, 추천, 분류 등 다양한 작업을 수행할 수 있게 하는 핵심 기술입니다.

> 🔎 **중요:**  
> pgvector는 **임베딩을 생성하지 않습니다.**  
> 임베딩 생성은 반드시 **DB 바깥(애플리케이션 · 임베딩 서비스 · LLM 서버)** 에서 수행해야 합니다.  
> pgvector의 역할은 **이미 생성된 임베딩을 저장하고, 인덱싱하며, 유사도 검색을 수행하는 것**입니다.
>
> 또한 **데이터를 저장할 때 사용한 임베딩 모델과, 사용자 질의를 임베딩할 때 사용하는 모델은 반드시 동일해야 합니다.**  
> 모델이 다르면 차원 수가 다르거나 의미 공간이 달라져 **유사도 검색이 무의미해지거나 잘못된 결과를 반환합니다.**

---

## 1) 전체 처리 흐름

pgvector를 활용한 전형적인 RAG / 의미 기반 검색 파이프라인은 다음과 같습니다.

**원본 데이터 → 임베딩 생성 → pgvector에 저장 → 쿼리 텍스트 임베딩 생성 → pgvector 유사도 검색 → 결과 + LLM 응답**

1. 원본 문서/텍스트/이미지 수집
2. 외부 임베딩 모델로 벡터 생성 (임베딩 서비스)
3. 생성된 벡터를 PostgreSQL + pgvector에 저장
4. 사용자가 질의(자연어 쿼리)를 입력하면 동일한 모델로 임베딩 생성
5. pgvector에서 `ORDER BY embedding <-> :query_vec` 로 유사도 검색
6. 검색 결과를 그대로 보여주거나, LLM에게 전달해 **요약·답변·추천** 생성

---

## 2) 텍스트 임베딩 생성

텍스트 임베딩(Text Embedding)은 문장, 단어, 문서를 숫자 벡터로 변환하는 과정입니다.

### 예: SentenceTransformers (온프레)

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("BAAI/bge-large-en-v1.5")

text = "Feeding rate significantly impacts fish growth under varying temperature."
vec = model.encode(text)
```

### 🔹 예: OpenAI API로 임베딩 생성

```python
from openai import OpenAI

client = OpenAI()

response = client.embeddings.create(
    model="text-embedding-3-small",
    input="안녕하세요."
)

embedding = response.data[0].embedding
print(len(embedding))   # 1536차원
```

이렇게 생성한 `embedding` 벡터를 그대로 `vector(n)` 컬럼에 저장하면 된다.

---

## 3) 이미지 임베딩 생성

이미지 임베딩은 이미지의 시각적 특징을 벡터로 표현한 것입니다.  
검색, 유사 이미지 탐지, RAG(이미지 기반) 시스템 등에서 활용됩니다.

### 🔹 예: CLIP 모델로 이미지 임베딩 생성

```python
import torch
import clip
from PIL import Image

model, preprocess = clip.load("ViT-B/32")

image = preprocess(Image.open("sample.jpg")).unsqueeze(0)
with torch.no_grad():
    embedding = model.encode_image(image)

embedding = embedding[0].tolist()
print(len(embedding))  # 512차원
```

---

## 4) float32 / half / binary 임베딩 비교

pgvector는 여러 타입의 벡터를 지원합니다.

| 타입 | 설명 | 장점 | 단점 |
|------|------|------|------|
| **vector (float32)** | 32bit float 벡터 | 가장 정확함 | 저장 공간/메모리 사용량 큼 |
| **halfvec (float16)** | 16bit float | 용량 약 50% 절감 | 약간의 정확도 손실 |
| **bit (binary)** | 이진 양자화 벡터 | 매우 빠르고 작음 | 정밀도 손실 크고, 튜닝 필요 |

### 왜 다양한 타입을 사용하는가?

- **float32** → 검색 정확도 최우선, 데이터 규모가 상대적으로 작거나 GPU/메모리 여유가 있을 때
- **half** → 정확도는 크게 떨어지지 않으면서 메모리 절약이 필요한 중대형 서비스
- **binary** → 수억~수십억 벡터를 다루는 초대규모 시스템, 빠른 1차 거친 검색(coarse search)에 유리

---

## 5) 임베딩 차원(Dimension)

임베딩은 모델마다 고정된 차원을 갖습니다. (예: 384, 768, 1024, 1536, 3072 등)

| 모델 | 차원 | 설명 |
|------|------|------|
| MiniLM | 384 | 가볍고 빠른 범용 임베딩 |
| KoSentenceBERT | 768 | 한국어 특화 문장 임베딩 |
| BERT-base | 768 | 전통 NLP 모델, 실험/연구용 |
| OpenAI text-embedding-3-small | 1536 | 범용 검색/RAG에 최적 |
| OpenAI text-embedding-3-large | 3072 | 고정확도, 데이터 품질이 중요한 서비스용 |

### 차원이 크면?

- 더 많은 의미/문맥을 담을 수 있어 표현력이 좋아짐
- 하지만 메모리, 저장 공간, 연산 비용도 함께 증가
- 서비스 특성과 예산에 맞춰 **차원 수와 모델을 선택**해야 한다.

---

## 6) 클라우드 / 온프레미스 환경별 임베딩 모델 추천

아래 표는 **pgvector를 사용할 때 많이 쓰이거나, 실무에서 권장되는 임베딩 모델**을 환경별로 정리한 것입니다.

| 환경 | 모델명 | 차원 수 | 특징 / 용도 |
|------|--------|--------|-------------|
| **클라우드** | OpenAI `text-embedding-3-small` | 1536 | 범용 RAG/검색에 가장 많이 사용, 비용 대비 성능 우수 |
| **클라우드** | OpenAI `text-embedding-3-large` | 3072 | 고성능·고정확도, 중요한 의사결정/검색 품질이 필요한 서비스 |
| **클라우드** | Cohere `embed-multilingual-v3` (또는 유사 모델) | 1024 | 다국어 지원, 문서/검색/RAG에 적합 |
| **온프레미스** | `sentence-transformers/all-MiniLM-L6-v2` | 384 | 가벼운 CPU/온프레 환경에 최적, 빠르고 실용적인 성능 |
| **온프레미스** | `jhgan/ko-sbert-sts` | 768 | 한국어 문장 유사도/검색에 특화, 국내 서비스에 적합 |
| **온프레미스** | `BAAI/bge-m3` 또는 `intfloat/e5-large-v2` | 1024~1024+ | 고성능 RAG/검색용, GPU 서버 기반 온프레 환경에서 자주 사용 |

> 📌 실제 프로젝트에서는  
> “서비스 특성(한국어/다국어), 예산, 레이턴시, GPU 보유 여부”  
> 를 기준으로 위 모델 중 1~2개를 선택한 뒤,  
> 해당 모델의 차원 수에 맞게 **`vector(n)` 컬럼을 정의**하면 된다.

---

## 6) 외부 임베딩 모델 활용과 pgvector 연계

pgvector는 임베딩 생성 기능이 없고, **외부 모델로 생성한 임베딩을 저장/검색하는 기능만 제공**합니다.

### 대표적인 임베딩 생성 모델과 연계 방식

#### 📌 SentenceTransformers (Python, 오픈소스)
- 빠르고 무료, 다양한 언어/도메인 지원
- 온프레미스 환경에서 가장 많이 사용

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("jhgan/ko-sbert-sts")  # 한국어 특화
vec = model.encode("안녕하세요.")
```

#### 📌 OpenAI Embedding API (클라우드)
- 정확도 우수, RAG/검색용으로 설계
- 클라우드 기반 서비스에 적합

```python
from openai import OpenAI

client = OpenAI()
client.embeddings.create(model="text-embedding-3-small", input="example")
```

#### 📌 CLIP, EVA-CLIP (이미지/텍스트 멀티모달)
- 이미지 검색 / 비디오 분석 / 멀티모달 RAG에서 활용
- 임베딩은 pgvector에 저장, 원본 파일은 객체 스토리지나 NAS에 저장

---

# 🎯 요약

- pgvector는 **임베딩을 생성하지 않고**, 외부 모델이 만든 벡터를 **저장·인덱싱·검색**하는 역할을 담당한다.
- 전체 흐름은  
  **원본 데이터 → 임베딩 생성 → pgvector 저장 → 쿼리 임베딩 생성 → 유사도 검색 → LLM 응답**  
  구조로 설계하는 것이 가장 이상적이다.
- 클라우드에서는 OpenAI 계열, 온프레미스에서는 SentenceTransformers/KoSBERT/BGE/E5 계열 모델이 실무에서 많이 사용된다.
- 선택한 임베딩 모델의 차원 수에 맞춰 `vector(n)` 컬럼을 정의하고, 동일한 모델로 쿼리 임베딩도 생성해야 의미 있는 검색 결과를 얻을 수 있다.

---

향후 장(04. 벡터 타입, 05. 벡터 저장, 06. 벡터 쿼리)에서는  
이렇게 생성된 임베딩을 pgvector에 **어떻게 저장하고, 어떤 방식으로 검색하고, 인덱싱할지**를 다룬다.
