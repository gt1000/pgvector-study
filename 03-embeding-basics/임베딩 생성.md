# 📘 03. 임베딩 생성 (Embedding Basics)

임베딩(Embedding)은 텍스트, 이미지, 오디오와 같은 비정형 데이터를 **숫자 벡터 형태로 변환**하여  
AI 모델이 의미 기반 검색, 추천, 분류 등 다양한 작업을 수행할 수 있게 하는 핵심 기술입니다.

> 🔎 **중요:**  
> pgvector는 **임베딩을 생성하지 않습니다.**  
> 임베딩 생성은 반드시 **DB 바깥(애플리케이션 · 임베딩 서비스 · LLM 서버)** 에서 수행해야 합니다.  
> pgvector의 역할은 **이미 생성된 임베딩을 저장하고, 인덱싱하며, 유사도 검색을 수행하는 것**입니다.
>
> 또한 **데이터를 저장할 때 사용한 임베딩 모델과, 사용자 질의를 임베딩할 때 사용하는 모델은 반드시 동일해야 합니다.**  
> 모델이 다르면 차원 수가 다르거나 의미 공간이 달라져 **유사도 검색이 무의미해지거나 잘못된 결과를 반환합니다.**

---

## 1) 전체 처리 흐름

pgvector를 활용한 전형적인 RAG / 의미 기반 검색 파이프라인은 다음과 같습니다.

**원본 데이터 → 임베딩 생성 → pgvector에 저장 → 쿼리 텍스트 임베딩 생성 → pgvector 유사도 검색 → 결과 + LLM 응답**

① 원본 문서/텍스트/이미지 수집  
② 외부 임베딩 모델로 벡터 생성 (임베딩 서비스)  
③ 생성된 벡터를 PostgreSQL + pgvector에 저장  
④ 사용자가 질의(자연어 쿼리)를 입력하면 동일한 모델로 임베딩 생성  
⑤ pgvector에서 `ORDER BY embedding <-> :query_vec` 로 유사도 검색  
⑥ 검색 결과를 그대로 보여주거나, LLM에게 전달해 **요약·답변·추천** 생성  
---

## 2) 텍스트 임베딩 생성

텍스트 임베딩(Text Embedding)은 문장, 단어, 문서를 숫자 벡터로 변환하는 과정입니다.

### 🔹 예: OpenAI API로 임베딩 생성

```python
from openai import OpenAI

client = OpenAI()

response = client.embeddings.create(
    model="text-embedding-3-small",
    input="안녕하세요."
)

embedding = response.data[0].embedding
print(len(embedding))   # 1536차원
```

### 예: SentenceTransformers (온프레)

```python
from sentence_transformers import SentenceTransformer
import psycopg2

# 1) 최신 임베딩 모델 로드 (추천)
model = SentenceTransformer("nomic-ai/nomic-embed-text-v1.5")

# 2) 텍스트 준비
text = "Feeding rate significantly impacts fish growth under varying temperature."

# 3) 임베딩 생성 (numpy → list)
vec = model.encode(text)
embedding_list = vec.tolist()

# 4) PostgreSQL 연결 및 INSERT
conn = psycopg2.connect(... 생략 ...)
cur = conn.cursor()

# 5) INSERT 실행 (차원 수정 필요: 768)
sql = """
    INSERT INTO research_docs (chunk_text, embedding)
    VALUES (%s, %s::vector(768))
"""
cur.execute(sql, (text, embedding_list))
```

이렇게 생성한 `embedding` 벡터를 그대로 `vector(n)` 컬럼에 저장하면 된다.

---

## 3) 이미지 임베딩 생성

이미지 임베딩은 이미지의 시각적 특징을 벡터로 표현한 것입니다.  
검색, 유사 이미지 탐지, RAG(이미지 기반) 시스템 등에서 활용됩니다.

### 🔹 예: CLIP 모델로 이미지 임베딩 생성

```python
import torch
import clip
from PIL import Image

model, preprocess = clip.load("ViT-B/32")

image = preprocess(Image.open("sample.jpg")).unsqueeze(0)
with torch.no_grad():
    embedding = model.encode_image(image)

embedding = embedding[0].tolist()
print(len(embedding))  # 512차원
```

---

## 4) float32 / half / binary 임베딩 비교

pgvector는 여러 타입의 벡터를 지원합니다.

| 타입 | 설명 | 장점 | 단점 |
|------|------|------|------|
| **vector (float32)** | 32bit float 벡터 | 가장 정확함 | 저장 공간/메모리 사용량 큼 |
| **halfvec (float16)** | 16bit float | 용량 약 50% 절감 | 약간의 정확도 손실 |
| **bit (binary)** | 이진 양자화 벡터 | 매우 빠르고 작음 | 정밀도 손실 크고, 튜닝 필요 |

### 왜 다양한 타입을 사용하는가?

- **float32** → 검색 정확도 최우선, 데이터 규모가 상대적으로 작거나 GPU/메모리 여유가 있을 때
- **half** → 정확도는 크게 떨어지지 않으면서 메모리 절약이 필요한 중대형 서비스
> **정확도 손실이 작은 이유**   
벡터 검색에서는 절대적인 값보다 **상대적인 거리/순위**가 중요하므로 Top-10 결과 중 8~9개는 float32와 동일합니다.
> ```
  > float32: 1.234567890... (소수점 7자리)
  > float16: 1.234500000... (소수점 3-4자리)
> ```
- **binary** → 수억~수십억 벡터를 다루는 초대규모 시스템, 빠른 1차 거친 검색(coarse search)에 유리. 대략적인 방향만 잡음

---

## 5) 임베딩 차원(Dimension)

임베딩은 모델마다 고정된 차원을 갖습니다. (예: 384, 768, 1024, 1536, 3072 등)

| 모델 | 차원 | 설명 |
|------|------|------|
| MiniLM | 384 | 가볍고 빠른 범용 임베딩 |
| KoSentenceBERT | 768 | 한국어 특화 문장 임베딩 |
| BERT-base | 768 | 전통 NLP 모델, 실험/연구용 |
| OpenAI text-embedding-3-small | 1536 | 범용 검색/RAG에 최적 |
| OpenAI text-embedding-3-large | 3072 | 고정확도, 데이터 품질이 중요한 서비스용 |

### 차원이 크면?

- 더 많은 의미/문맥을 담을 수 있어 표현력이 좋아짐
- 하지만 메모리, 저장 공간, 연산 비용도 함께 증가
- 서비스 특성과 예산에 맞춰 **차원 수와 모델을 선택**해야 한다.

---

## 6) 클라우드 / 온프레미스 환경별 임베딩 모델 추천

아래 표는 **pgvector를 사용할 때 많이 쓰이거나, 실무에서 권장되는 임베딩 모델**을 환경별로 정리한 것입니다.

| 환경 | 모델명 | 차원 수 | 특징 / 용도 |
|------|--------|--------|-------------|
| **클라우드** | OpenAI `text-embedding-3-small` | 512~1536 | 범용 RAG/검색에 가장 많이 사용, 비용 대비 성능 우수 |
| **클라우드** | OpenAI `text-embedding-3-large` | 256~3072 | 최고 성능, 차원 조절 가능 (MRL 지원) |
| **클라우드** | Cohere `embed-v3` | 1024 | 다국어 지원, 압축 기능, 하이브리드 검색 최적화 |
| **온프레미스** | `nomic-ai/nomic-embed-text-v1.5` | 768 | 2024년 SOTA급 오픈소스, MRL 지원, 가볍고 빠름 |
| **온프레미스** | `BAAI/bge-m3` | 1024 | 다국어, 하이브리드 검색 지원, 높은 정확도 |
| **온프레미스** | `Alibaba-NLP/gte-Qwen2-7B` | 3584 | MTEB 벤치마크 최상위, 최고 성능 (GPU 필요) |

> 📌 실제 프로젝트에서는  
> “서비스 특성(한국어/다국어), 예산, 레이턴시, GPU 보유 여부”  
> 를 기준으로 위 모델 중 1~2개를 선택한 뒤,  
> 해당 모델의 차원 수에 맞게 **`vector(n)` 컬럼을 정의**하면 된다.

---

## 6) 외부 임베딩 모델 활용과 pgvector 연계

pgvector는 임베딩 생성 기능이 없고, **외부 모델로 생성한 임베딩을 저장/검색하는 기능만 제공**합니다.

### 대표적인 임베딩 생성 모델과 연계 방식

#### 📌 SentenceTransformers (Python, 오픈소스)
- 빠르고 무료, 다양한 언어/도메인 지원
- 온프레미스 환경에서 가장 많이 사용
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("BAAI/bge-m3")  # 2024년 최신 다국어
vec = model.encode("안녕하세요.")
```

#### 📌 OpenAI Embedding API (클라우드)
- 정확도 우수, RAG/검색용으로 설계
- 클라우드 기반 서비스에 적합
```python
from openai import OpenAI

client = OpenAI(api_key="your-api-key")
response = client.embeddings.create(
    model="text-embedding-3-small",
    input="example"
)
vec = response.data[0].embedding
```

#### 📌 CLIP (이미지/텍스트 멀티모달)
- 이미지 검색 / 비디오 분석 / 멀티모달 RAG에서 활용
- 임베딩은 pgvector에 저장, 원본 파일은 객체 스토리지나 NAS에 저장
```python
from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")

inputs = processor(text=["a photo of a cat"], return_tensors="pt")
vec = model.get_text_features(**inputs)
```

---

# 🎯 요약

- pgvector는 **임베딩을 생성하지 않고**, 외부 모델이 만든 벡터를 **저장·인덱싱·검색**하는 역할을 담당한다.
- 전체 흐름은  
  **원본 데이터 → 임베딩 생성 → pgvector 저장 → 쿼리 임베딩 생성 → 유사도 검색 → LLM 응답**  
  구조로 설계하는 것이 가장 이상적이다.
- 클라우드에서는 OpenAI 계열, 온프레미스에서는 SentenceTransformers/KoSBERT/BGE/E5 계열 모델이 실무에서 많이 사용된다.
- 선택한 임베딩 모델의 차원 수에 맞춰 `vector(n)` 컬럼을 정의하고, 동일한 모델로 쿼리 임베딩도 생성해야 의미 있는 검색 결과를 얻을 수 있다.

---